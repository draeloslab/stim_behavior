{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "from PIL import Image\n",
    "import yaml\n",
    "import pickle\n",
    "from utils import *\n",
    "from helpers import *\n",
    "\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from proSVD import proSVD\n",
    "from dlclive import DLCLive, Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"octo-2-unlabelled-small\"\n",
    "with open(f'configs/{config_file}.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "IS_METADATA_PRESENT = (config['path']['xls'] is not None)\n",
    "files_info = None\n",
    "filenames = None\n",
    "\n",
    "fps = config['info']['fps']\n",
    "\n",
    "root_dir = config['path']['root']\n",
    "video_dir = f\"{root_dir}/{config['path']['video']}\"\n",
    "\n",
    "if IS_METADATA_PRESENT:\n",
    "    xls_path = f\"{root_dir}/{config['path']['xls']}\"\n",
    "    files_info = read_octopus_xlsx(xls_path)\n",
    "    files_info = files_info[files_info['Stim Method'] == 'Electrical']\n",
    "    filenames = files_info[\"File Name\"].to_list()\n",
    "else:\n",
    "    filenames = [os.path.splitext(file)[0] for file in os.listdir(video_dir)]\n",
    "\n",
    "###\n",
    "\n",
    "working_dir = f\"{root_dir}/{config['path']['working']}\" # to save processed data and figures\n",
    "\n",
    "model_path = f\"{root_dir}/{config['path']['model']}\"\n",
    "\n",
    "dlc_live = DLCLive(\n",
    "    model_path,\n",
    "    processor=Processor(),\n",
    "    pcutoff=0.2,\n",
    "    resize=1)\n",
    "\n",
    "PROSVD_K = 4 # no. of dims to reduce to\n",
    "\n",
    "TIME_MARGIN = (-120, 180) # to trim videos\n",
    "total_f = TIME_MARGIN[1] - TIME_MARGIN[0]\n",
    "\n",
    "init_frame_crop = 10 # No of initial frames used to set cropping info\n",
    "init_frame_prosvd = 90 # No of initial frames used to initialize proSVD\n",
    "init_frame = init_frame_crop + init_frame_prosvd\n",
    "\n",
    "\n",
    "DEV_MODE = False\n",
    "if DEV_MODE:\n",
    "    files_info = files_info.iloc[[0,3,13,14,15,16]] #[3:4]\n",
    "    filenames = files_info[\"File Name\"].to_list()\n",
    "\n",
    "print(f\"Processing {len(filenames)} videos from {video_dir}\")\n",
    "if len(filenames) < 4:\n",
    "    print('\\t', end='')\n",
    "    print(*filenames, sep=\"\\n\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fig_dir(filename):\n",
    "    figs_dir = f\"{working_dir}/figs\"\n",
    "    os.makedirs(figs_dir, exist_ok=True)\n",
    "    return figs_dir\n",
    "\n",
    "def get_data_dir(filename):\n",
    "    data_dir = f\"{working_dir}/data/{filename}\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    return data_dir\n",
    "\n",
    "def is_badpose(likely, threshold=0.8):\n",
    "    return np.mean(likely) < threshold\n",
    "\n",
    "def calculate_nancount(data):\n",
    "    nan_count = np.sum(np.isnan(data))\n",
    "    return 100*nan_count/data.size\n",
    "\n",
    "def fill_nan_linear_interpolation_axis(arr, axis):\n",
    "    def fill_nan_linear_interpolation(row):\n",
    "        nan_mask = np.isnan(row)\n",
    "        indices = np.arange(len(row))\n",
    "        row[nan_mask] = np.interp(indices[nan_mask], indices[~nan_mask], row[~nan_mask])\n",
    "        return row\n",
    "    \n",
    "    return np.apply_along_axis(fill_nan_linear_interpolation, axis, arr)\n",
    "\n",
    "class DataManager:\n",
    "    def __init__(self):\n",
    "        self.data = {\n",
    "            'Q': []\n",
    "        }\n",
    "    \n",
    "    def _print_key_error(self, key):\n",
    "        print(f\"Key '{key}' does not exist in the data manager.\")\n",
    "\n",
    "    def add_nan(self, key, shape):\n",
    "        data_ = self.data[key]\n",
    "        pop_count = 0\n",
    "        while len(data_) > 0 and data_[-1] is None:\n",
    "            data_.pop()\n",
    "            pop_count += 1\n",
    "        while pop_count > 0:\n",
    "            data_.append(np.full(shape, np.nan))\n",
    "            pop_count -= 1\n",
    "\n",
    "    def add(self, key, value):\n",
    "        if key in self.data:\n",
    "            if value is not None:\n",
    "                self.add_nan(key, value.shape)\n",
    "            self.data[key].append(value)\n",
    "        else:\n",
    "            self._print_key_error(key)\n",
    "\n",
    "    def to_numpy(self):\n",
    "        for key in self.data:\n",
    "            data_ = self.data[key]\n",
    "            if len(data_) == 0 or data_[0] is None:\n",
    "                self.data[key] = None\n",
    "                return\n",
    "            self.add_nan(key, data_[0].shape)\n",
    "            self.data[key] = np.array(data_)\n",
    "\n",
    "    def remove(self, key):\n",
    "        if key in self.data:\n",
    "            del self.data[key]\n",
    "        else:\n",
    "            self._print_key_error(key)\n",
    "\n",
    "    def get(self, key):\n",
    "        if key in self.data:\n",
    "            return self.data[key]\n",
    "        else:\n",
    "            self._print_key_error(key)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_idx in tqdm(range(2)):\n",
    "    row = files_info.iloc[video_idx]\n",
    "    md = load_metadata_new(row, time_margin = TIME_MARGIN)\n",
    "\n",
    "    start_f, end_f = md[0], md[1]\n",
    "    total_f = end_f - start_f\n",
    "\n",
    "    video_filename = filenames[video_idx]\n",
    "\n",
    "    video = None\n",
    "\n",
    "    try:\n",
    "        video = load_video(video_dir, video_filename)\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, start_f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    figs_dir = get_fig_dir(video_filename)\n",
    "    data_dir = get_data_dir(video_filename)\n",
    "\n",
    "    crop_box = np.zeros(4, int)\n",
    "\n",
    "    index = -1\n",
    "\n",
    "    frames = []  # for proSVD initialization\n",
    "    dm = DataManager()\n",
    "    pro = None\n",
    "\n",
    "    while video.isOpened():\n",
    "        index += 1\n",
    "        if index >= total_f:\n",
    "            break\n",
    "\n",
    "        ret, frame = video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Cropping starts\n",
    "        if index < init_frame_crop:\n",
    "            crop_box += detect_crop_box_wrapper(dlc_live, frame, index, margin=max(40, int(frame.size//(3*5*1e4))))\n",
    "            continue\n",
    "\n",
    "        if index == init_frame_crop:\n",
    "            crop_box //= init_frame_crop\n",
    "\n",
    "        frame2 = frame[crop_box[0]:crop_box[1],crop_box[2]:crop_box[3],:]\n",
    "\n",
    "        # Cropping ends\n",
    "\n",
    "        pose = detect_pose(dlc_live, frame, index)\n",
    "\n",
    "        frame2 = rgb_to_grayscale(frame2)\n",
    "        frame2 = downsample_image(frame2)\n",
    "\n",
    "        # save the cropped frame for checking if cropping done correctly\n",
    "        if index == init_frame_crop:\n",
    "            crop_dir = f'{figs_dir}/cropped'\n",
    "            os.makedirs(crop_dir, exist_ok=True)\n",
    "            im = Image.fromarray(frame2)\n",
    "            im.save(f'{crop_dir}/{video_filename}.png')\n",
    "\n",
    "        frame2 = frame2.flatten()\n",
    "\n",
    "        if index < init_frame:\n",
    "            frames.append(frame2)\n",
    "            continue\n",
    "\n",
    "        # proSVD starts\n",
    "\n",
    "        if index == init_frame:\n",
    "            frames = np.array(frames).T\n",
    "            pro = proSVD(k=PROSVD_K, w_len=1,history=0, decay_alpha=1, trueSVD=True)\n",
    "            pro.initialize(frames)\n",
    "            del frames\n",
    "\n",
    "        if is_badpose(pose[...,-1]):\n",
    "            dm.add('Q', None)\n",
    "            continue\n",
    "\n",
    "        pro.preupdate()\n",
    "        pro.updateSVD(frame2[:, None])\n",
    "        pro.postupdate()\n",
    "\n",
    "        # pro_coordi = frame2 @ pro.Q\n",
    "        dm.add('Q', pro.Q)\n",
    "\n",
    "    video.release()\n",
    "\n",
    "    dm.to_numpy()\n",
    "    np.save(f'{data_dir}/Q.npy', dm.get('Q'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(files_info['Stimulation Class'].value_counts())\n",
    "display(files_info['Classification'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Post processing!\n",
    "\n",
    "# stim_class_list = sorted(files_info['Stimulation Class'].unique().tolist())\n",
    "# stim_count = len(stim_class_list)\n",
    "\n",
    "# movement_types = [\n",
    "#     \"No movement\",\n",
    "#     \"Movement\",\n",
    "#     \"Movement with arm curl\"\n",
    "# ]\n",
    "\n",
    "# tx = np.arange(init_frame + TIME_MARGIN[0], TIME_MARGIN[1])/fps\n",
    "\n",
    "# err_log = {\n",
    "#     'poor_pose': [],\n",
    "#     'file_missing': []\n",
    "# }\n",
    "\n",
    "# feature_all = []\n",
    "# label_all = []\n",
    "\n",
    "# for video_idx in tqdm(range(len(filenames))):\n",
    "#     video_filename = filenames[video_idx]\n",
    "\n",
    "#     figs_dir = get_fig_dir(video_filename)\n",
    "#     data_dir = get_data_dir(video_filename)\n",
    "\n",
    "#     try:\n",
    "#         Q_full = np.load(f'{data_dir}/Q.npy')\n",
    "#     except ValueError:\n",
    "#         err_log['poor_pose'].append(video_filename)\n",
    "#         continue\n",
    "#     except FileNotFoundError:\n",
    "#         err_log['file_missing'].append(video_filename)\n",
    "#         continue\n",
    "#     except:\n",
    "#         raise(\"Uncaught exception\")\n",
    "\n",
    "#     total_frames = Q_full.shape[0]\n",
    "\n",
    "#     row = None\n",
    "#     if IS_METADATA_PRESENT:\n",
    "#         row = files_info.iloc[video_idx]\n",
    "\n",
    "#     stim_class = row[\"Stimulation Class\"]\n",
    "\n",
    "#     Q_diff = np.diff(Q_full, axis=0)\n",
    "#     Q_norm_diff = np.linalg.norm(Q_diff, axis=1)\n",
    "#     Q_norm_diff = np.insert(Q_norm_diff, 0, 0, axis=0)\n",
    "\n",
    "#     move_idx = int(row['Classification'])\n",
    "#     stim_idx = stim_class_list.index(stim_class)\n",
    "\n",
    "#     feature_all.append(Q_norm_diff)\n",
    "#     label_all.append(stim_idx)\n",
    "\n",
    "#     del Q_full\n",
    "#     del Q_diff\n",
    "#     del Q_norm_diff\n",
    "\n",
    "# df = pd.DataFrame({\n",
    "#     'features': feature_all,\n",
    "#     'labels': label_all,\n",
    "# })\n",
    "\n",
    "# with open(f'data/pro_features.pkl', 'wb') as f:\n",
    "#     pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'data/pro_features.pkl', 'rb') as f:\n",
    "    df_features = pickle.load(f)\n",
    "print(df_features['features'].iloc[0].shape)\n",
    "df_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot 2: all experiments separately with basis as separate plots\n",
    "\n",
    "# stim_class_list = sorted(files_info['Stimulation Class'].unique().tolist())\n",
    "# stim_count = len(stim_class_list)\n",
    "\n",
    "# num_figures = PROSVD_K\n",
    "# num_rows = int(np.ceil(np.sqrt(num_figures)))\n",
    "# num_cols = num_figures//num_rows\n",
    "\n",
    "# movement_types = [\n",
    "#     \"No movement\",\n",
    "#     \"Movement\",\n",
    "#     \"Movement with arm curl\"\n",
    "# ]\n",
    "\n",
    "# fig_all = []\n",
    "# axs_all = []\n",
    "\n",
    "# num_lines = 3 # for 3 movement classes\n",
    "# colors = plt.cm.Blues(np.linspace(0.2, 1, num=num_lines))\n",
    "\n",
    "# titles = [\n",
    "#     \"n-Norm of t-Diff of Q\",\n",
    "# ]\n",
    "\n",
    "# tx = np.arange(init_frame + TIME_MARGIN[0], TIME_MARGIN[1])/fps\n",
    "\n",
    "# err_log = {\n",
    "#     'poor_pose': [],\n",
    "#     'file_missing': []\n",
    "# }\n",
    "\n",
    "# for r in range(1): \n",
    "#     fig, axs = plt.subplots(num_rows, num_cols, figsize=(8, 6), gridspec_kw={'top': 0.8})\n",
    "#     fig_all.append(fig)\n",
    "#     axs_all.append(axs)\n",
    "\n",
    "# feature_all = []\n",
    "# label_all = []\n",
    "\n",
    "# for video_idx in tqdm(range(len(filenames))):\n",
    "#     video_filename = filenames[video_idx]\n",
    "\n",
    "#     figs_dir = get_fig_dir(video_filename)\n",
    "#     data_dir = get_data_dir(video_filename)\n",
    "\n",
    "#     try:\n",
    "#         Q_full = np.load(f'{data_dir}/Q.npy')\n",
    "#     except ValueError:\n",
    "#         err_log['poor_pose'].append(video_filename)\n",
    "#         continue\n",
    "#     except FileNotFoundError:\n",
    "#         err_log['file_missing'].append(video_filename)\n",
    "#         continue\n",
    "#     except:\n",
    "#         raise(\"Uncaught exception\")\n",
    "\n",
    "#     total_frames = Q_full.shape[0]\n",
    "\n",
    "#     row = None\n",
    "#     if IS_METADATA_PRESENT:\n",
    "#         row = files_info.iloc[video_idx]\n",
    "\n",
    "#     stim_class = row[\"Stimulation Class\"]\n",
    "\n",
    "#     metadata = load_metadata(video_filename, total_frames, row, fps, init_frame)\n",
    "\n",
    "#     Q_diff = np.diff(Q_full, axis=0)\n",
    "#     Q_norm_diff = np.linalg.norm(Q_diff, axis=1)\n",
    "#     Q_norm_diff = np.insert(Q_norm_diff, 0, 0, axis=0)\n",
    "\n",
    "#     move_class = int(row['Classification'])\n",
    "#     stim_idx = stim_class_list.index(stim_class)\n",
    "\n",
    "#     feature_all.append(Q_norm_diff[:, 1])\n",
    "#     label_all.append(stim_idx)\n",
    "\n",
    "#     ## PLOTTING ##\n",
    "\n",
    "#     data = [\n",
    "#         Q_norm_diff,\n",
    "#     ]\n",
    "\n",
    "#     start_f = metadata['start']['f']\n",
    "#     end_f = metadata['end']['f']\n",
    "\n",
    "#     for r in range(len(titles)):\n",
    "#         for i in range(num_rows):\n",
    "#             for j in range(num_cols):\n",
    "#                 k = j + i*num_rows\n",
    "#                 data_ = data[r][:, k]\n",
    "#                 # data_ = smooth_data(data_, kernel_size = 3)\n",
    "#                 axs_all[m][i, j].plot(tx, data_, c=colors[move_class], alpha=0.7, label=move_class, linewidth=1)\n",
    "#                 axs_all[m][i, j].set_title(f'Basis {k}')\n",
    "\n",
    "#     for x in data:\n",
    "#         del x\n",
    "\n",
    "#     del Q_full\n",
    "\n",
    "# feature_all = np.array(feature_all)\n",
    "# label_all = np.array(label_all)\n",
    "            \n",
    "    \n",
    "# # legend_elements = [Line2D([0], [0], color=colors[i], lw=4, label=movement_types[i]) for i in range(3)]\n",
    "\n",
    "# # ylims = [1e-2, 4e-1, 4e-1, 4e-1]\n",
    "# # for r in range(len(titles)):\n",
    "# #     fig_all[r].legend(handles=legend_elements, loc='upper right')\n",
    "# #     fig_all[r].subplots_adjust(top=0.9, bottom=0.1, left=0.1, right=0.9, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# #     for i in range(num_rows):\n",
    "# #         for j in range(num_cols):\n",
    "# #             # axs_all[r][i].set_ylim(0, ylims[r])\n",
    "# #             axs_all[r][i, j].axvline(x=0, color='orange', linewidth=2, alpha=0.3)\n",
    "# #             axs_all[r][-1, j].set_xlabel(\"Time (s)\")\n",
    "\n",
    "# #     fig_all[r].suptitle(f'All Data')\n",
    "\n",
    "# #     figs_dir_full = f'{figs_dir}/{titles[r]}'\n",
    "# #     os.makedirs(figs_dir_full, exist_ok=True)\n",
    "# #     fig_all[r].savefig(f'{figs_dir_full}/all_data.png', facecolor='white')\n",
    "\n",
    "# # for key, items in err_log.items():\n",
    "# #     print(f\"{key}: {len(items)}\")\n",
    "# #     for item in items:\n",
    "# #         print(f\"\\t{item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# Load and preprocess the data\n",
    "with open(f'data/pro_features.pkl', 'rb') as f:\n",
    "    df_features = pickle.load(f)\n",
    "X = np.stack(df_features['features'].values, axis=-1)\n",
    "X = X.reshape(-1, X.shape[-1]).T\n",
    "# linear interpolation to fill nan values\n",
    "X = fill_nan_linear_interpolation_axis(X, axis=1)\n",
    "\n",
    "y = df_features['labels'].values.astype(int)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, X_train.shape[2]), activation='relu'))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=4, verbose=0);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "# Perform predictions on the test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "class_names = le.classes_\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=class_names)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "first_words = [string.split()[0] for string in stim_class_list]\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=first_words, yticklabels=first_words)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Stimulation point of contact - using proSVD')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
