{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "from PIL import Image\n",
    "import yaml\n",
    "from utils import *\n",
    "from helpers import *\n",
    "import pickle\n",
    "\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dlclive import DLCLive, Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self, keys=[]):\n",
    "        self.data = {key: [] for key in keys}\n",
    "    \n",
    "    def _print_key_error(self, key):\n",
    "        print(f\"Key '{key}' does not exist in the data manager.\")\n",
    "\n",
    "    def add_nan(self, key, shape):\n",
    "        data_ = self.data[key]\n",
    "        pop_count = 0\n",
    "        while len(data_) > 0 and data_[-1] is None:\n",
    "            data_.pop()\n",
    "            pop_count += 1\n",
    "        while pop_count > 0:\n",
    "            data_.append(np.full(shape, np.nan))\n",
    "            pop_count -= 1\n",
    "\n",
    "    def add(self, key, value):\n",
    "        if key in self.data:\n",
    "            if value is not None:\n",
    "                self.add_nan(key, value.shape)\n",
    "            self.data[key].append(value)\n",
    "        else:\n",
    "            self._print_key_error(key)\n",
    "\n",
    "    def to_numpy(self):\n",
    "        for key in self.data:\n",
    "            data_ = self.data[key]\n",
    "            if len(data_) == 0 or data_[0] is None:\n",
    "                self.data[key] = None\n",
    "                return\n",
    "            self.add_nan(key, data_[0].shape)\n",
    "            self.data[key] = np.array(data_)\n",
    "\n",
    "    def save(self, dir):\n",
    "        for key in self.data:\n",
    "            np.save(f'{dir}/{key}.npy', self.data.get(key))\n",
    "\n",
    "    def load(self, dir, keys):\n",
    "        if keys is None:\n",
    "            keys = self.data.keys\n",
    "        for key in keys:\n",
    "            self.data[key] = np.load(f'{dir}/{key}.npy')\n",
    "        return self.data\n",
    "\n",
    "    def remove(self, key):\n",
    "        if key in self.data:\n",
    "            del self.data[key]\n",
    "        else:\n",
    "            self._print_key_error(key)\n",
    "\n",
    "    def get(self, key):\n",
    "        if key in self.data:\n",
    "            return self.data[key]\n",
    "        else:\n",
    "            self._print_key_error(key)\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLCManager:\n",
    "    def __init__(self, \n",
    "            model_path,\n",
    "            processor=Processor(),\n",
    "            pcutoff=0.2,\n",
    "            resize=1):\n",
    "        \n",
    "        self.model = DLCLive(\n",
    "            model_path=model_path,\n",
    "            processor=processor,\n",
    "            pcutoff=pcutoff,\n",
    "            # display=True,\n",
    "            resize=resize)\n",
    "        self.frame = None\n",
    "        self.is_first_frame = None\n",
    "        self.dm = DataManager()\n",
    "\n",
    "    def init_data(self, feature_keys):\n",
    "        self.dm = DataManager(feature_keys)\n",
    "        self.prev_pose_xy = None\n",
    "        \n",
    "    def update_frame(self, frame, is_first_frame):\n",
    "        self.frame = frame\n",
    "        self.is_first_frame = is_first_frame\n",
    "        \n",
    "    def detect_pose_helper(self):\n",
    "        if self.is_first_frame:\n",
    "            pose = self.model.init_inference(self.frame)\n",
    "        else:\n",
    "            pose = self.model.get_pose(self.frame)\n",
    "        return pose\n",
    "        \n",
    "    def detect_pose(self):\n",
    "        curr_pose = self.detect_pose_helper()\n",
    "        \n",
    "        curr_pose_xy, curr_pose_p = curr_pose[:, :-1], curr_pose[:, -1]\n",
    "        if self.prev_pose_xy is None:\n",
    "            self.prev_pose_xy = curr_pose_xy\n",
    "\n",
    "        pose = np.stack([self.prev_pose_xy, curr_pose_xy])\n",
    "        feature_angles_item, pose_speed_item = extract_pose_features(pose)\n",
    "\n",
    "        self.dm.add('xy', curr_pose_xy)\n",
    "        self.dm.add('p', curr_pose_p)\n",
    "        self.dm.add('angles', feature_angles_item)\n",
    "        self.dm.add('speed', pose_speed_item)\n",
    "\n",
    "        self.prev_pose_xy = curr_pose_xy\n",
    "\n",
    "    def save_data(self, dir):\n",
    "        self.dm.to_numpy()\n",
    "        self.dm.save(dir)\n",
    "\n",
    "    def load_data(self, dir, feature_keys):\n",
    "        return self.dm.load(dir, feature_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Driver:\n",
    "    def __init__(self, config_file, dev_mode = False, verbose = True):\n",
    "        with open(f'configs/{config_file}.yaml', 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        self.is_metadata_present = (config['path']['xls'] is not None)\n",
    "        self.fps = config['info']['fps']\n",
    "        root_dir = config['path']['root']\n",
    "        self.video_dir = f\"{root_dir}/{config['path']['video']}\"\n",
    "\n",
    "        if self.is_metadata_present:\n",
    "            xls_path = f\"{root_dir}/{config['path']['xls']}\"\n",
    "            self.files_info = read_octopus_xlsx(xls_path)\n",
    "            self.files_info = self.files_info[self.files_info['Stim Method'] == 'Electrical']\n",
    "            self.filenames = self.files_info[\"File Name\"].to_list()\n",
    "        else:\n",
    "            self.filenames = [os.path.splitext(file)[0] for file in os.listdir(self.video_dir)]\n",
    "\n",
    "        self.working_dir = f\"{root_dir}/{config['path']['working']}\" # to save processed data and figures\n",
    "\n",
    "        model_path = f\"{root_dir}/{config['path']['model']}\"\n",
    "\n",
    "        self.feature_keys = ['xy', 'p', 'angles', 'speed']\n",
    "        self.dlc = DLCManager(model_path)\n",
    "        \n",
    "        self.prosvd_k = 4 # no. of dims to reduce to\n",
    "\n",
    "        self.time_margin = (-120, 180) # to trim videos\n",
    "        self.total_f = self.time_margin[1] - self.time_margin[0]\n",
    "\n",
    "        self.init_frame_crop = 10 # No of initial frames used to set cropping info\n",
    "        self.init_frame_prosvd = 90 # No of initial frames used to initialize proSVD\n",
    "        self.init_frame = self.init_frame_crop + self.init_frame_prosvd\n",
    "\n",
    "        self.tx = np.arange(self.init_frame + self.time_margin[0], self.time_margin[1])/self.fps\n",
    "\n",
    "        if self.is_metadata_present:\n",
    "            self.stim_class_list = sorted(self.files_info['Stimulation Class'].unique().tolist())\n",
    "        else:\n",
    "            self.stim_class_list = np.array(['Cord Electrical', 'Distal Electrical', 'Proximal Electrical'])\n",
    "\n",
    "        if dev_mode:\n",
    "            self.files_info = self.files_info.iloc[[2]]\n",
    "            self.filenames = self.files_info[\"File Name\"].to_list()\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Processing {len(self.filenames)} videos from {self.video_dir}\")\n",
    "            if len(self.filenames) < 4:\n",
    "                print('\\t', end='')\n",
    "                print(*self.filenames, sep=\"\\n\\t\")\n",
    "\n",
    "    def get_fig_dir(self, filename):\n",
    "        figs_dir = f\"{self.working_dir}/figs\"\n",
    "        os.makedirs(figs_dir, exist_ok=True)\n",
    "        return figs_dir\n",
    "\n",
    "    def get_data_dir(self, filename=None):\n",
    "        if filename is None:\n",
    "            data_dir = f\"{self.working_dir}\"\n",
    "        else:\n",
    "            data_dir = f\"{self.working_dir}/data/{filename}\"\n",
    "        os.makedirs(data_dir, exist_ok=True)\n",
    "        return data_dir\n",
    "    \n",
    "    def load_video(self, video_idx):\n",
    "        video_filename = self.filenames[video_idx]\n",
    "\n",
    "        self.video = None\n",
    "        try:\n",
    "            self.video = load_video(self.video_dir, video_filename)\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "        self.index = -1\n",
    "\n",
    "        self.dlc.init_data(feature_keys=self.feature_keys)\n",
    "\n",
    "        return (self.video is not None)\n",
    "    \n",
    "    def is_video_empty(self):\n",
    "        return self.video is None or not self.video.isOpened()\n",
    "    \n",
    "    def read_video(self):\n",
    "        ret, self.frame = self.video.read()\n",
    "        self.index += 1\n",
    "        self.dlc.update_frame(self.frame, self.index == 0)\n",
    "        return ret\n",
    "    \n",
    "    def release_video(self):\n",
    "        self.video.release()\n",
    "    \n",
    "    def detect_pose(self):\n",
    "        self.dlc.detect_pose()\n",
    "\n",
    "    def save_data(self, video_idx):\n",
    "        video_filename = self.filenames[video_idx]\n",
    "        data_dir = self.get_data_dir(video_filename)\n",
    "        self.dlc.save_data(data_dir)\n",
    "\n",
    "    def post_process(self, verbose=False):\n",
    "        err_log = {\n",
    "            'poor_pose': [],\n",
    "            'file_missing': []\n",
    "        }\n",
    "\n",
    "        columns = ['filename', *self.feature_keys, 'move_class', 'stim_class']\n",
    "        df = pd.DataFrame(columns=columns)\n",
    "\n",
    "        for video_idx in range(len(self.filenames)):\n",
    "            video_filename = self.filenames[video_idx]\n",
    "\n",
    "            data_dir = self.get_data_dir(video_filename)\n",
    "\n",
    "            try:\n",
    "                features = self.dlc.load_data(data_dir, self.feature_keys)\n",
    "            except ValueError:\n",
    "                err_log['poor_pose'].append(video_filename)\n",
    "                continue\n",
    "            except FileNotFoundError:\n",
    "                err_log['file_missing'].append(video_filename)\n",
    "                continue\n",
    "            except:\n",
    "                raise(\"Uncaught exception\")\n",
    "            \n",
    "            row = None\n",
    "            if self.is_metadata_present:\n",
    "                row = self.files_info.iloc[video_idx]\n",
    "            md = load_metadata_new(row, time_margin = self.time_margin)\n",
    "\n",
    "            start_f, end_f = self.init_frame + md[0], md[1]\n",
    "\n",
    "            data = {}\n",
    "\n",
    "            for key, value in features.items():\n",
    "                data[key] = value[start_f: end_f, ...]\n",
    "\n",
    "            move_idx, stim_idx = 0, 0\n",
    "            if self.is_metadata_present:\n",
    "                move_idx = int(row['Classification'])\n",
    "                stim_class = row[\"Stimulation Class\"]\n",
    "                stim_idx = self.stim_class_list.index(stim_class)\n",
    "\n",
    "            data['filename'] = video_filename\n",
    "            data['move_class'] = move_idx\n",
    "            data['stim_class'] = stim_idx\n",
    "\n",
    "            df = df.append(data, ignore_index=True)\n",
    "\n",
    "        if verbose:\n",
    "            for key, items in err_log.items():\n",
    "                print(f\"{key}: {len(items)}\")\n",
    "                for item in items:\n",
    "                    print(f\"\\t{item}\")\n",
    "\n",
    "        data_dir = self.get_data_dir()\n",
    "\n",
    "        feature_key_tuple = [('features', key) for key in self.feature_keys]\n",
    "\n",
    "        df.columns = pd.MultiIndex.from_tuples([\n",
    "            ('metadata', 'filename'),\n",
    "            *feature_key_tuple,\n",
    "            ('labels', 'move_class'),\n",
    "            ('labels', 'stim_class')\n",
    "        ])\n",
    "\n",
    "        # df = df.fillna(0)\n",
    "\n",
    "        with open(f'{data_dir}/features.pkl', 'wb') as f:\n",
    "            pickle.dump(df, f)\n",
    "\n",
    "    def visualize_results(self):\n",
    "        num_lines = 3 # for 3 angles\n",
    "        colors = plt.cm.Paired(np.linspace(0, 1, num=num_lines))\n",
    "\n",
    "        num_rows, num_cols = 1, 3\n",
    "        fig, axs = plt.subplots(num_rows, num_cols, figsize=(16, 4), gridspec_kw={'top': 0.85})\n",
    "\n",
    "        for i, key in enumerate(self.feature_angles_dict.keys()):\n",
    "            feature_angle_mean = np.mean(self.feature_angles_dict[key], axis=0)\n",
    "\n",
    "            for k in range(3):\n",
    "                data = feature_angle_mean[..., k]\n",
    "                data = smooth_data(data, 5)\n",
    "                axs[i].plot(data, label=k, linewidth=2, c=colors[k])\n",
    "            axs[i].set_ylim(-10, 190)\n",
    "            axs[i].set_title(key)\n",
    "            axs[i].set_xlabel(\"Time (s)\")\n",
    "            axs[i].axvline(x=0, color='orange', linewidth=2, alpha=0.3)\n",
    "\n",
    "        legend_elements = [Line2D([0], [0], color=colors[i], lw=4, label=i) for i in range(3)]\n",
    "        fig.legend(title=\"Angle\", handles=legend_elements, loc='upper right')\n",
    "        fig.suptitle(f'Electrical Stimulations - Angle')\n",
    "\n",
    "        figs_dir = self.get_fig_dir(\"\")\n",
    "        figs_dir_full = f'{figs_dir}/dlc-summary'\n",
    "        os.makedirs(figs_dir_full, exist_ok=True)\n",
    "        fig.savefig(f'{figs_dir_full}/Electrical Stimulations - Angle.png', facecolor='white')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = Driver(\"octo-2-unlabelled-small\", dev_mode = False)\n",
    "driver = Driver(\"octo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for video_idx in tqdm(range(len(driver.filenames))):\n",
    "#     ret = driver.load_video(video_idx)\n",
    "#     if not ret:\n",
    "#         continue\n",
    "\n",
    "#     while not driver.is_video_empty():\n",
    "#         ret = driver.read_video()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         driver.detect_pose()\n",
    "\n",
    "#     driver.release_video()\n",
    "\n",
    "#     driver.save_data(video_idx)\n",
    "\n",
    "# driver.post_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = driver.get_data_dir()\n",
    "with open(f'{data_dir}/features.pkl', 'rb') as f:\n",
    "    df_features = pickle.load(f)\n",
    "print(df_features.shape)\n",
    "display(df_features.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative analysis of DLC performance\n",
    "\n",
    "p_like = XY = df_features['features', 'p'].values\n",
    "XY = df_features['features', 'xy'].values\n",
    "\n",
    "N = len(p_like)\n",
    "\n",
    "def plot_scatter(xy):\n",
    "    colors = plt.cm.Blues(np.linspace(1, 0.2, num=xy.shape[0]))\n",
    "    for i, (x, y) in enumerate(xy):\n",
    "        plt.scatter(x, -y, color=colors[i], label=f\"Point {i+1}\")\n",
    "\n",
    "    plt.gca().set_aspect('equal')\n",
    "    # plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "err_list = []\n",
    "\n",
    "for i in range(N):\n",
    "    p_el = p_like[i]\n",
    "\n",
    "    feat = XY[i]\n",
    "\n",
    "    # plot_scatter(feat[0])\n",
    "\n",
    "    feat = np.diff(feat, axis=-2)\n",
    "    feat = np.square(feat)\n",
    "    \n",
    "    feat = np.sqrt(np.sum(feat, axis=-1))\n",
    "\n",
    "    L = np.sum(feat, axis=-1, keepdims=True)\n",
    "\n",
    "    feat /= L\n",
    "\n",
    "    IDEAL_LENGTH = np.array([1/2, 1/4, 1/8, 1/8])\n",
    "\n",
    "    err_1 = 1 - p_el.mean()\n",
    "    err_2 = np.var(L)/np.mean(L)\n",
    "    err_2 = min(err_2, 1)\n",
    "\n",
    "    err_3 = feat - IDEAL_LENGTH\n",
    "    err_3 = np.linalg.norm(err_3, axis=-1)\n",
    "    err_3 = np.mean(err_3)\n",
    "\n",
    "    err_list.append([err_1, err_2, err_3])\n",
    "\n",
    "err_list = np.array(err_list).T\n",
    "\n",
    "print(\"Fraction of good data:\")\n",
    "print(f\"1: {100*np.sum(err_list[0]<0.2)/N : 0.1f}%\")\n",
    "print(f\"2: {100*np.sum(err_list[1]<0.1)/N : 0.1f}%\")\n",
    "print(f\"All: {100*np.sum((err_list[0]<0.2) & (err_list[1]<0.1))/N : 0.1f}%\")\n",
    "\n",
    "plt.plot(err_list[0], label=\"Error 1\")\n",
    "plt.plot(err_list[1], label=\"Error 2\")\n",
    "plt.plot(err_list[2], label=\"Error 3\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY = df_features['features', 'xy'].values\n",
    "N = len(XY)\n",
    "mean_angle = np.zeros(N)\n",
    "max_angle = np.zeros(N)\n",
    "mean_angular_speed = np.zeros(N)\n",
    "max_angular_speed = np.zeros(N)\n",
    "\n",
    "for i in range(len(XY)):\n",
    "    feat = XY[i]\n",
    "    feat = np.diff(feat, axis=-2)\n",
    "    angle_array = np.zeros(feat.shape[0])\n",
    "    for t in range(feat.shape[0]):\n",
    "        angle_array[t] = angle_between(feat[t, 0], feat[t, -1])\n",
    "\n",
    "    mean_angle[i] = np.mean(angle_array)\n",
    "    max_angle[i] = np.max(angle_array)\n",
    "    angular_speed = driver.fps * 1e-3 * np.abs(np.diff(angle_array))\n",
    "    mean_angular_speed[i] = np.mean(angular_speed)\n",
    "    max_angular_speed[i] = np.max(angular_speed)\n",
    "    \n",
    "df_final = pd.DataFrame({\n",
    "    'Mean angle' : mean_angle, \n",
    "    'Max angle' : max_angle,\n",
    "    'Mean angular speed' : mean_angular_speed, \n",
    "    'Max angular speed' : max_angular_speed})\n",
    "\n",
    "result_concat = pd.concat([df_final, df_features['labels']], axis=1)\n",
    "\n",
    "display(result_concat.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_unit(feature):\n",
    "    if 'angle' in feature:\n",
    "        return '°'\n",
    "    elif 'angular speed' in feature:\n",
    "        return '°/ms'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = df_final.columns.to_list()\n",
    "features_to_compare = [\n",
    "    [features_list[0], features_list[1]],\n",
    "    [features_list[2], features_list[3]],\n",
    "    [features_list[0], features_list[2]],\n",
    "    [features_list[1], features_list[3]]\n",
    "]\n",
    "features_to_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrical Stimulations - Movement\n",
    "\n",
    "num_rows, num_cols = 2, 2\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(8, 8), gridspec_kw={'top': 0.85})\n",
    "\n",
    "movement_types = [\n",
    "    \"No movement\",\n",
    "    \"Movement\",\n",
    "    \"Movement with arm curl\"\n",
    "]\n",
    "class_type = 'move_class'\n",
    "\n",
    "class_list = movement_types\n",
    "no_of_points = len(class_list)\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 1, num=no_of_points))\n",
    "\n",
    "for c in range(no_of_points):\n",
    "    class_data = result_concat.query(f'{class_type} == {c}')\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            k = i*num_cols + j\n",
    "            to_compare = features_to_compare[k]\n",
    "            x_lb, y_lb = to_compare\n",
    "\n",
    "            axs[i, j].scatter(class_data[x_lb], class_data[y_lb],\n",
    "                color=colors[c], label=class_list[c], s=20)\n",
    "            \n",
    "            axs[i, j].set_xlabel(f'{x_lb} ({find_unit(x_lb)})')\n",
    "            axs[i, j].set_ylabel(f'{y_lb} ({find_unit(y_lb)})')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], color=colors[i], lw=4, label=class_list[i]) for i in range(no_of_points)]\n",
    "fig.legend(title=\"\", handles=legend_elements, loc='upper right')\n",
    "fig.suptitle(f'Electrical Stimulations - Movement')\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Electrical Stimulations - Location\n",
    "\n",
    "num_rows, num_cols = 2, 2\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(8, 8), gridspec_kw={'top': 0.85})\n",
    "\n",
    "class_type = 'stim_class'\n",
    "\n",
    "class_list = driver.stim_class_list\n",
    "no_of_points = len(class_list)\n",
    "colors = plt.cm.Paired(np.linspace(0.2, 0.8, num=no_of_points))\n",
    "\n",
    "for c in range(no_of_points):\n",
    "    class_data = result_concat.query(f'{class_type} == {c}')\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            k = i*num_cols + j\n",
    "            to_compare = features_to_compare[k]\n",
    "            x_lb, y_lb = to_compare\n",
    "\n",
    "            axs[i, j].scatter(class_data[x_lb], class_data[y_lb],\n",
    "                color=colors[c], label=class_list[c], s=20)\n",
    "            \n",
    "            axs[i, j].set_xlabel(f'{x_lb} ({find_unit(x_lb)})')\n",
    "            axs[i, j].set_ylabel(f'{y_lb} ({find_unit(y_lb)})')\n",
    "\n",
    "legend_elements = [Line2D([0], [0], color=colors[i], lw=4, label=class_list[i]) for i in range(no_of_points)]\n",
    "fig.legend(title=\"\", handles=legend_elements, loc='upper right')\n",
    "fig.suptitle(f'Electrical Stimulations - Location')\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = df_final.to_numpy()  # 56 samples with 4 features each\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = 'move_class'\n",
    "\n",
    "class_list = movement_types\n",
    "no_of_points = len(class_list)\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 1, num=no_of_points))\n",
    "\n",
    "for c in range(no_of_points):\n",
    "    indices = result_concat.query(f'{class_type} == {c}').index\n",
    "    class_data = reduced_data[indices]\n",
    "    plt.scatter(class_data[:, 0], class_data[:, 1],\n",
    "                color=colors[c], label=class_list[c], s=25)\n",
    "            \n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.title(f'Electrical Stimulations - Movement')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_type = 'stim_class'\n",
    "\n",
    "class_list = driver.stim_class_list\n",
    "no_of_points = len(class_list)\n",
    "colors = plt.cm.Paired(np.linspace(0.2, 0.8, num=no_of_points))\n",
    "\n",
    "for c in range(no_of_points):\n",
    "    indices = result_concat.query(f'{class_type} == {c}').index\n",
    "    class_data = reduced_data[indices]\n",
    "    plt.scatter(class_data[:, 0], class_data[:, 1],\n",
    "                color=colors[c], label=class_list[c], s=25)\n",
    "            \n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.title(f'Electrical Stimulations - Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering - KMeans\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data = reduced_data\n",
    "\n",
    "NO_OF_CLUSTERS = 3\n",
    "# Create a KMeans instance with 3 clusters\n",
    "kmeans = KMeans(n_clusters=NO_OF_CLUSTERS, random_state=42)\n",
    "\n",
    "# Fit the KMeans model to the data and predict the cluster labels\n",
    "cluster_labels = kmeans.fit_predict(data)\n",
    "\n",
    "# Get the cluster centers (centroids)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "for c in range(NO_OF_CLUSTERS): \n",
    "    # Separate the data points by cluster\n",
    "    cluster_data = data[cluster_labels == c]\n",
    "    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f'Cluster {c+1}', color=colors[c])\n",
    "\n",
    "# Plot the cluster centers\n",
    "plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], marker='X', s=100, c='black', label='Centroids')\n",
    "\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Clustering with K-Means')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering - AgglomerativeClustering\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "data = reduced_data\n",
    "\n",
    "NO_OF_CLUSTERS = 3\n",
    "# Create a KMeans instance with 3 clusters\n",
    "agg_clustering = AgglomerativeClustering(n_clusters=NO_OF_CLUSTERS)\n",
    "\n",
    "# Fit the KMeans model to the data and predict the cluster labels\n",
    "cluster_labels = agg_clustering.fit_predict(data)\n",
    "\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "for c in range(NO_OF_CLUSTERS): \n",
    "    # Separate the data points by cluster\n",
    "    cluster_data = data[cluster_labels == c]\n",
    "    plt.scatter(cluster_data[:, 0], cluster_data[:, 1], label=f'Cluster {c+1}', color=colors[c])\n",
    "\n",
    "# Plot the cluster centers\n",
    "# plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], marker='X', s=100, c='black', label='Centroids')\n",
    "\n",
    "plt.xlabel(\"PC 1\")\n",
    "plt.ylabel(\"PC 2\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Agglomerative Clustering')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['label', 'cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['label', 'cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot angles and p-likelihood\n",
    "\n",
    "# N = 2\n",
    "# X = df_features['features', 'angles'].values[N-1:N]\n",
    "# y = df_features['labels'].iloc[N-1:N]\n",
    "\n",
    "# movement_types = [\n",
    "#     \"No movement\",\n",
    "#     \"Movement\",\n",
    "#     \"Movement with arm curl\"\n",
    "# ]\n",
    "\n",
    "# tx = driver.tx\n",
    "\n",
    "# stim_class_list = driver.stim_class_list\n",
    "\n",
    "# for i in range(1):\n",
    "#     feature = X[i]\n",
    "#     label = y.iloc[i]\n",
    "#     print(df_features['metadata', 'filename'].iloc[i])\n",
    "#     print(movement_types[label['move_class']],\"|\", stim_class_list[label['stim_class']])\n",
    "#     for k in range(feature.shape[-1]):\n",
    "#         plt.plot(tx, X[i][:, k], label=k)\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "# X = df_features['features', 'p'].values[N-1:N]\n",
    "# y = df_features['labels'].iloc[N-1:N]\n",
    "\n",
    "# movement_types = [\n",
    "#     \"No movement\",\n",
    "#     \"Movement\",\n",
    "#     \"Movement with arm curl\"\n",
    "# ]\n",
    "\n",
    "# tx = driver.tx\n",
    "\n",
    "# stim_class_list = driver.stim_class_list\n",
    "\n",
    "# for i in range(1):\n",
    "#     feature = X[i]\n",
    "#     label = y.iloc[i]\n",
    "#     for k in range(feature.shape[-1]):\n",
    "#         plt.plot(tx, X[i][:, k], label=k)\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib tk\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "# WIDTH, HEIGHT = 640, 480\n",
    "\n",
    "# R = 1\n",
    "# df_ = df_features.iloc[R]\n",
    "# print(df_['metadata', 'filename'])\n",
    "# xy = df_['features', 'xy']\n",
    "# x_coords, y_coords = xy[..., 0], xy[..., 1]\n",
    "\n",
    "# y_coords = HEIGHT-y_coords\n",
    "\n",
    "# num_points = xy.shape[1]  # Number of points to visualize\n",
    "\n",
    "# # Create a figure and axis\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# colors = plt.cm.Blues(np.linspace(1, 0.2, num=num_points))\n",
    "\n",
    "# # Create an empty scatter plot for each point\n",
    "# scatters = [ax.scatter([], [], color=colors[i]) for i in range(num_points)]\n",
    "\n",
    "# # Set up the axis limits\n",
    "# ax.set_xlim(0, WIDTH)\n",
    "# ax.set_ylim(0, HEIGHT)\n",
    "\n",
    "# # Function to update the scatter plots\n",
    "# def update_plots(i):\n",
    "#     # Iterate through each point\n",
    "#     for j in range(num_points):\n",
    "#         # Get the current x and y coordinates for the point\n",
    "#         x = x_coords[i, j]\n",
    "#         y = y_coords[i, j]\n",
    "        \n",
    "#         # Update the scatter plot data for the point\n",
    "#         scatters[j].set_offsets([(x, y)])\n",
    "        \n",
    "#     # Set the title to the current index\n",
    "#     ax.set_title(f\"Time Step: {driver.tx[i]:0.1f} s\")\n",
    "    \n",
    "#     # Pause for a short duration (in seconds) to observe each point\n",
    "#     plt.pause(1.5*1/30)\n",
    "\n",
    "# # Iterate through each time step and update the plots\n",
    "# for i in range(xy.shape[0]):\n",
    "#     update_plots(i)\n",
    "\n",
    "# # Show the final plots in a new window\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['labels', 'move_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# Load and preprocess the data\n",
    "X = np.stack(df_features['features', 'angles'].values, axis=-1)\n",
    "X = X.reshape(-1, X.shape[-1]).T\n",
    "y = df_features['labels', 'stim_class'].values.astype(int)\n",
    "\n",
    "# Encode the target variable\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(y)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Reshape the input data for LSTM\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(1, X_train.shape[2]), activation='relu'))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=4, verbose=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)\n",
    "\n",
    "# Perform predictions on the test data\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "class_names = [0, 1, 2]\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=class_names)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "first_words = [string.split()[0] for string in driver.stim_class_list]\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=first_words, yticklabels=first_words)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Stimulation point of contact - using DLC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
