{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project \"/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-06-03\" already exists!\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "\n",
    "config_path = deeplabcut.create_new_project(\n",
    "    'FESFatigue', \n",
    "    'Jake', \n",
    "    ['/home/jakejoseph/Desktop/Joseph_Code/FESNewCameraclips-Jake-2024-05-05/videos/fatiguetest0523ecrb12_2.mp4'], \n",
    "    working_directory='/home/jakejoseph/Desktop/Joseph_Code/', \n",
    "    copy_videos=True, \n",
    "    multianimal=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-07 12:19:13.496485: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-07 12:19:13.757908: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-07 12:19:13.808516: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-06-07 12:19:13.808548: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-06-07 12:19:13.883392: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-07 12:19:14.707926: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-06-07 12:19:14.707971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-06-07 12:19:14.707975: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.9...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "config_path = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/config.yaml'\n",
    "# deeplabcut.add_new_videos(config_path, ['/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4','/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/napierecrbfatigue_05_31_3_1.mp4'])\n",
    "# deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: QOpenGLWidget: Failed to create context\n",
      "WARNING: QOpenGLWidget: Failed to create context\n",
      "WARNING: QOpenGLWidget: Failed to create context\n",
      "WARNING: QOpenGLWidget: Failed to create context\n",
      "WARNING: composeAndFlush: QOpenGLContext creation failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: OpenGL version could not be determined, which might be a sign that OpenGL is not loaded correctly.\n",
      "WARNING: Error drawing visual <vispy.visuals.mesh.MeshVisual object at 0x7e7ae662e550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/app/backends/_qt.py\", line 553, in wheelEvent\n",
      "    self._vispy_canvas.events.mouse_wheel(\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/util/event.py\", line 453, in __call__\n",
      "    self._invoke_callback(cb, event)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/util/event.py\", line 471, in _invoke_callback\n",
      "    _handle_exception(self.ignore_callback_errors,\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/util/event.py\", line 469, in _invoke_callback\n",
      "    cb(event)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/napari/_vispy/canvas.py\", line 97, in _process_mouse_event\n",
      "    super()._process_mouse_event(event)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 354, in _process_mouse_event\n",
      "    picked = self.visual_at(event.pos)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 407, in visual_at\n",
      "    id_ = self._render_picking((fbpos[0], fbpos[1], 1, 1))\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 492, in _render_picking\n",
      "    img = self.render(bgcolor=(0, 0, 0, 0), crop=crop)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 264, in render\n",
      "    self._draw_scene(bgcolor=bgcolor)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 277, in _draw_scene\n",
      "    self.draw_visual(self.scene)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 315, in draw_visual\n",
      "    node.draw()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/visuals.py\", line 103, in draw\n",
      "    self._visual_superclass.draw(self)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/visuals/visual.py\", line 605, in draw\n",
      "    v.draw()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/visuals/visual.py\", line 451, in draw\n",
      "    self._program.draw(self._vshare.draw_mode,\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/visuals/shaders/program.py\", line 102, in draw\n",
      "    Program.draw(self, *args, **kwargs)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/program.py\", line 543, in draw\n",
      "    canvas.context.flush_commands()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/context.py\", line 172, in flush_commands\n",
      "    self.glir.flush(self.shared.parser)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 584, in flush\n",
      "    self._shared.flush(parser)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 506, in flush\n",
      "    parser.parse(self._filter(self.clear(), parser))\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 824, in parse\n",
      "    self._parse(command)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 798, in _parse\n",
      "    ob.attach(*args)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 1795, in attach\n",
      "    self.deactivate()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 1766, in deactivate\n",
      "    gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, stack[-1])\n",
      "IndexError: list index out of range\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: Error drawing visual <vispy.visuals.mesh.MeshVisual object at 0x7e7ae662e550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/app/backends/_qt.py\", line 553, in wheelEvent\n",
      "    self._vispy_canvas.events.mouse_wheel(\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/util/event.py\", line 453, in __call__\n",
      "    self._invoke_callback(cb, event)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/util/event.py\", line 471, in _invoke_callback\n",
      "    _handle_exception(self.ignore_callback_errors,\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/util/event.py\", line 469, in _invoke_callback\n",
      "    cb(event)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/napari/_vispy/canvas.py\", line 97, in _process_mouse_event\n",
      "    super()._process_mouse_event(event)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 354, in _process_mouse_event\n",
      "    picked = self.visual_at(event.pos)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 407, in visual_at\n",
      "    id_ = self._render_picking((fbpos[0], fbpos[1], 1, 1))\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 492, in _render_picking\n",
      "    img = self.render(bgcolor=(0, 0, 0, 0), crop=crop)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 264, in render\n",
      "    self._draw_scene(bgcolor=bgcolor)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 277, in _draw_scene\n",
      "    self.draw_visual(self.scene)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/canvas.py\", line 315, in draw_visual\n",
      "    node.draw()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/scene/visuals.py\", line 103, in draw\n",
      "    self._visual_superclass.draw(self)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/visuals/visual.py\", line 605, in draw\n",
      "    v.draw()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/visuals/visual.py\", line 451, in draw\n",
      "    self._program.draw(self._vshare.draw_mode,\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/visuals/shaders/program.py\", line 102, in draw\n",
      "    Program.draw(self, *args, **kwargs)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/program.py\", line 543, in draw\n",
      "    canvas.context.flush_commands()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/context.py\", line 172, in flush_commands\n",
      "    self.glir.flush(self.shared.parser)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 584, in flush\n",
      "    self._shared.flush(parser)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 506, in flush\n",
      "    parser.parse(self._filter(self.clear(), parser))\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 824, in parse\n",
      "    self._parse(command)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 800, in _parse\n",
      "    ob.set_framebuffer(*args)\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 1752, in set_framebuffer\n",
      "    self.deactivate()\n",
      "  File \"/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.8/site-packages/vispy/gloo/glir.py\", line 1766, in deactivate\n",
      "    gl.glBindFramebuffer(gl.GL_FRAMEBUFFER, stack[-1])\n",
      "IndexError: list index out of range\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n",
      "WARNING: composeAndFlush: makeCurrent() failed\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 9,  7, 18, 19, 12, 14,  4,  8, 13, 11,  1,  3,  6, 10, 17,  0, 15,\n",
       "           5, 16]),\n",
       "   array([2])))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path, augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/FESFatigue_Jake95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 2000,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/Documentation_data-FESFatigue_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2024-05-31 13:13:25.295182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-31 13:13:25.295349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-05-31 13:13:25.295388: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-05-31 13:13:25.295417: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-05-31 13:13:25.295443: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-05-31 13:13:25.315447: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-05-31 13:13:25.315498: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-05-31 13:13:25.315503: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-05-31 13:13:25.316461: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-31 13:13:25.486385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-31 13:13:25.486472: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 13:13:25.963131: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4]], 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/FESFatigue_Jake95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 2000, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/Documentation_data-FESFatigue_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 5, 'pos_dist_thresh': 17, 'project_path': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0569 lr: 0.005\n",
      "iteration: 200 loss: 0.0183 lr: 0.005\n",
      "iteration: 300 loss: 0.0163 lr: 0.005\n",
      "iteration: 400 loss: 0.0156 lr: 0.005\n",
      "iteration: 500 loss: 0.0149 lr: 0.005\n",
      "iteration: 600 loss: 0.0150 lr: 0.005\n",
      "iteration: 700 loss: 0.0135 lr: 0.005\n",
      "iteration: 800 loss: 0.0131 lr: 0.005\n",
      "iteration: 900 loss: 0.0130 lr: 0.005\n",
      "iteration: 1000 loss: 0.0119 lr: 0.005\n",
      "iteration: 1100 loss: 0.0118 lr: 0.005\n",
      "iteration: 1200 loss: 0.0108 lr: 0.005\n",
      "iteration: 1300 loss: 0.0104 lr: 0.005\n",
      "iteration: 1400 loss: 0.0106 lr: 0.005\n",
      "iteration: 1500 loss: 0.0096 lr: 0.005\n",
      "iteration: 1600 loss: 0.0104 lr: 0.005\n",
      "iteration: 1700 loss: 0.0093 lr: 0.005\n",
      "iteration: 1800 loss: 0.0091 lr: 0.005\n",
      "iteration: 1900 loss: 0.0091 lr: 0.005\n",
      "iteration: 2000 loss: 0.0091 lr: 0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplayiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaveiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:284\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix, superanimal_name, superanimal_transfer_learning)\u001b[0m\n\u001b[1;32m    273\u001b[0m         train(\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;28mstr\u001b[39m(poseconfigfile),\n\u001b[1;32m    275\u001b[0m             displayiters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m             allow_growth\u001b[38;5;241m=\u001b[39mallow_growth,\n\u001b[1;32m    281\u001b[0m         )  \u001b[38;5;66;03m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;28mstr\u001b[39m(start_path))\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:273\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix, superanimal_name, superanimal_transfer_learning)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_estimation_tensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelecting single-animal trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 273\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mposeconfigfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisplayiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43msaveiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmaxiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_snapshots_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeepdeconvweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdeconvweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py:287\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    284\u001b[0m     current_lr \u001b[38;5;241m=\u001b[39m lr_gen\u001b[38;5;241m.\u001b[39mget_lr(it \u001b[38;5;241m-\u001b[39m start_iter)\n\u001b[1;32m    285\u001b[0m     lr_dict \u001b[38;5;241m=\u001b[39m {learning_rate: current_lr}\n\u001b[0;32m--> 287\u001b[0m [_, loss_val, summary] \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_summaries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_dict\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m cum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_val\n\u001b[1;32m    291\u001b[0m train_writer\u001b[38;5;241m.\u001b[39madd_summary(summary, it)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, shuffle=1, displayiters=100, saveiters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESNewCameraApr19/FESNewCamera_Jake95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/dlc-models/iteration-0/FESNewCameraApr19-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESNewCameraApr19/FESNewCamera_Jake95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 2000,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESNewCameraApr19/Documentation_data-FESNewCamera_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/dlc-models/iteration-0/FESNewCameraApr19-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/jakejoseph/anaconda3/envs/DLCGPU/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_FESNewCameraApr19shuffle1_50000  with # of training iterations: 50000\n",
      "Running evaluation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:19,  1.03it/s]\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py:930: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  DataMachine.to_hdf(resultsfilename, \"df_with_missing\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-50000\n",
      "Results for 50000  training iterations: 95 1 train error: 2.36 pixels. Test error: 28.35  pixels.\n",
      "With pcutoff of 0.6  train error: 2.36 pixels. Test error: 33.95 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  DataCombined[loopscorer][bp][\"y\"][imagenr]\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:68: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + DataCombined[loopscorer][bp][\"x\"][imagenr]\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:71: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  int(DataCombined[loopscorer][bp][\"y\"][imagenr]),\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  int(DataCombined[loopscorer][bp][\"x\"][imagenr]),\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:75: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = DataCombined[loopscorer][bp][\"likelihood\"][imagenr]\n",
      "100%|| 20/20 [00:14<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2048x1536 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path,Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-2000 for model /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2024-06-03 10:17:06.392409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 10:17:06.392612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.392653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.392684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.392715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.413813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.413878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.413883: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-03 10:17:06.414816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 10:17:06.429121: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/videos/Individual Motor Points top 03-05.mp4\n",
      "Loading  /home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/videos/Individual Motor Points top 03-05.mp4\n",
      "Duration of video [s]:  2355.87 , recorded with  30.0 fps!\n",
      "Overall # of frames:  70676  found with (before cropping) frame dimensions:  2048 1536\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 2024/70676 [31:23<21:18:04,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "video = '/home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/videos/Individual Motor Points top 03-05.mp4'\n",
    "config_path = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/config.yaml'\n",
    "deeplabcut.analyze_videos(config_path, video, shuffle=1, save_as_csv=True, videotype='mp4')\n",
    "# deeplabcut.extract_outlier_frames(config_path, video,outlieralgorithm='uncertain',p_bound=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "It seems the model for iteration 0 and shuffle 1 and trainFraction 0.95 does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/predict_videos.py:509\u001b[0m, in \u001b[0;36manalyze_videos\u001b[0;34m(config, videos, videotype, shuffle, trainingsetindex, gputouse, save_as_csv, in_random_order, destfolder, batchsize, cropping, TFGPUinference, dynamic, modelprefix, robust_nframes, allow_growth, use_shelve, auto_track, n_tracks, calibrate, identity_only, use_openvino)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 509\u001b[0m     dlc_cfg \u001b[38;5;241m=\u001b[39m \u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_test_config\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/config.py:71\u001b[0m, in \u001b[0;36mload_config\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_config\u001b[39m(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpose_cfg.yaml\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcfg_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/config.py:49\u001b[0m, in \u001b[0;36mcfg_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mLoad a config from file filename and merge it into the default options.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     50\u001b[0m     yaml_cfg \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39mload(f, Loader\u001b[38;5;241m=\u001b[39myaml\u001b[38;5;241m.\u001b[39mSafeLoader)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-06-03/dlc-models/iteration-0/FESFatigueJun3-trainset95shuffle1/test/pose_cfg.yaml'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m video \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_as_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideotype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmp4\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# deeplabcut.create_labeled_video(config_path, video, videotype = 'mp4', save_frames=False)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/dlcv22/lib/python3.10/site-packages/deeplabcut/pose_estimation_tensorflow/predict_videos.py:511\u001b[0m, in \u001b[0;36manalyze_videos\u001b[0;34m(config, videos, videotype, shuffle, trainingsetindex, gputouse, save_as_csv, in_random_order, destfolder, batchsize, cropping, TFGPUinference, dynamic, modelprefix, robust_nframes, allow_growth, use_shelve, auto_track, n_tracks, calibrate, identity_only, use_openvino)\u001b[0m\n\u001b[1;32m    509\u001b[0m     dlc_cfg \u001b[38;5;241m=\u001b[39m load_config(\u001b[38;5;28mstr\u001b[39m(path_test_config))\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt seems the model for iteration \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and shuffle \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m and trainFraction \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;241m%\u001b[39m (iteration, shuffle, trainFraction)\n\u001b[1;32m    514\u001b[0m     )\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# Check which snapshots are available and sort them by # iterations\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: It seems the model for iteration 0 and shuffle 1 and trainFraction 0.95 does not exist."
     ]
    }
   ],
   "source": [
    "video = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31'\n",
    "deeplabcut.analyze_videos(config_path, video, shuffle=1, save_as_csv=True, videotype='mp4')\n",
    "# deeplabcut.create_labeled_video(config_path, video, videotype = 'mp4', save_frames=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/fatiguetest0523ecrb12_2.mp4'\n",
    "# deeplabcut.extract_outlier_frames(config_path, new_video)\n",
    "deeplabcut.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([29, 21,  4, 31, 25,  7, 32, 18, 30, 27, 20,  2, 19,  0, 14,  8, 26,\n",
       "          11,  1,  3, 10, 16, 34,  6, 22, 37, 12, 33, 17,  9, 23, 13, 15,  5,\n",
       "          36, 28]),\n",
       "   array([35, 24])))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deeplabcut.merge_datasets(config_path)\n",
    "deeplabcut.create_training_dataset(config_path, net_type='resnet_50', augmenter_type='imgaug')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLCGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
