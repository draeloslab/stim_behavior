{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project \"/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-06-03\" already exists!\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "\n",
    "config_path = deeplabcut.create_new_project(\n",
    "    'FESFatigue', \n",
    "    'Jake', \n",
    "    ['/home/jakejoseph/Desktop/Joseph_Code/FESNewCameraclips-Jake-2024-05-05/videos/fatiguetest0523ecrb12_2.mp4'], \n",
    "    working_directory='/home/jakejoseph/Desktop/Joseph_Code/', \n",
    "    copy_videos=True, \n",
    "    multianimal=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 14:04:40.190634: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 14:04:40.295018: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-10 14:04:40.311565: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-10 14:04:40.611285: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-06-10 14:04:40.611321: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-06-10 14:04:40.611324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.10...\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "config_path = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/config.yaml'\n",
    "# deeplabcut.add_new_videos(config_path, ['/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4','/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/napierecrbfatigue_05_31_3_1.mp4'])\n",
    "# deeplabcut.extract_frames(config_path, mode='automatic', algo='kmeans', userfeedback=False, crop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.label_frames(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([48, 74, 59, 54, 34, 26, 68, 33, 45, 69, 27, 60,  3, 42, 43,  7, 22,\n",
       "          41, 50, 38, 61, 53, 62, 56, 72,  6, 52, 70,  4, 30, 49,  2, 28, 11,\n",
       "          23, 10, 31, 40, 57,  1, 32, 66, 14, 76, 19, 29, 63, 35, 18,  0, 75,\n",
       "          15,  5, 55, 16, 51, 20, 71,  8, 13, 25, 37, 17, 24, 46, 39, 65, 58,\n",
       "          12, 36, 21,  9, 73]),\n",
       "   array([67, 64, 47, 44])))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(config_path, augmenter_type='imgaug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/FESFatigue_Jake95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 2000,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/Documentation_data-FESFatigue_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Batch Size is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2024-06-10 14:04:48.490881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.507838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.510259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.513084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 14:04:48.514026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.516075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.517522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.605175: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.606460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.607576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.608619: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-06-10 14:04:48.608638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9729 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ImageNet-pretrained resnet_50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 14:04:48.761475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.763062: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.764202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.765322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.766522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 14:04:48.767729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9729 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-06-10 14:04:49.166554: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'imgaug', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4]], 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'], 'alpha_r': 0.02, 'apply_prob': 0.5, 'contrast': {'clahe': True, 'claheratio': 0.1, 'histeq': True, 'histeqratio': 0.1, 'gamma': False, 'sigmoid': False, 'log': False, 'linear': False}, 'convolution': {'edge': False, 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]}, 'embossratio': 0.1, 'sharpen': False, 'sharpenratio': 0.3}, 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/FESFatigue_Jake95shuffle1.mat', 'decay_steps': 30000, 'display_iters': 1000, 'init_weights': '/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'lr_init': 0.0005, 'max_input_size': 2000, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/Documentation_data-FESFatigue_95shuffle1.pickle', 'min_input_size': 64, 'multi_stage': False, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 5, 'pos_dist_thresh': 17, 'project_path': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': (-90, 90)}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 14:04:50.707416: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8902\n",
      "2024-06-10 14:04:50.788116: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "iteration: 100 loss: 0.0531 lr: 0.005\n",
      "iteration: 200 loss: 0.0194 lr: 0.005\n",
      "iteration: 300 loss: 0.0181 lr: 0.005\n",
      "iteration: 400 loss: 0.0142 lr: 0.005\n",
      "iteration: 500 loss: 0.0149 lr: 0.005\n",
      "iteration: 600 loss: 0.0148 lr: 0.005\n",
      "iteration: 700 loss: 0.0137 lr: 0.005\n",
      "iteration: 800 loss: 0.0119 lr: 0.005\n",
      "iteration: 900 loss: 0.0121 lr: 0.005\n",
      "iteration: 1000 loss: 0.0115 lr: 0.005\n",
      "iteration: 1100 loss: 0.0124 lr: 0.005\n",
      "iteration: 1200 loss: 0.0111 lr: 0.005\n",
      "iteration: 1300 loss: 0.0104 lr: 0.005\n",
      "iteration: 1400 loss: 0.0114 lr: 0.005\n",
      "iteration: 1500 loss: 0.0096 lr: 0.005\n",
      "iteration: 1600 loss: 0.0093 lr: 0.005\n",
      "iteration: 1700 loss: 0.0099 lr: 0.005\n",
      "iteration: 1800 loss: 0.0096 lr: 0.005\n",
      "iteration: 1900 loss: 0.0097 lr: 0.005\n",
      "iteration: 2000 loss: 0.0107 lr: 0.005\n",
      "iteration: 2100 loss: 0.0096 lr: 0.005\n",
      "iteration: 2200 loss: 0.0100 lr: 0.005\n",
      "iteration: 2300 loss: 0.0094 lr: 0.005\n",
      "iteration: 2400 loss: 0.0086 lr: 0.005\n",
      "iteration: 2500 loss: 0.0085 lr: 0.005\n",
      "iteration: 2600 loss: 0.0078 lr: 0.005\n",
      "iteration: 2700 loss: 0.0081 lr: 0.005\n",
      "iteration: 2800 loss: 0.0080 lr: 0.005\n",
      "iteration: 2900 loss: 0.0076 lr: 0.005\n",
      "iteration: 3000 loss: 0.0083 lr: 0.005\n",
      "iteration: 3100 loss: 0.0092 lr: 0.005\n",
      "iteration: 3200 loss: 0.0073 lr: 0.005\n",
      "iteration: 3300 loss: 0.0079 lr: 0.005\n",
      "iteration: 3400 loss: 0.0089 lr: 0.005\n",
      "iteration: 3500 loss: 0.0077 lr: 0.005\n",
      "iteration: 3600 loss: 0.0079 lr: 0.005\n",
      "iteration: 3700 loss: 0.0081 lr: 0.005\n",
      "iteration: 3800 loss: 0.0075 lr: 0.005\n",
      "iteration: 3900 loss: 0.0069 lr: 0.005\n",
      "iteration: 4000 loss: 0.0080 lr: 0.005\n",
      "iteration: 4100 loss: 0.0080 lr: 0.005\n",
      "iteration: 4200 loss: 0.0067 lr: 0.005\n",
      "iteration: 4300 loss: 0.0074 lr: 0.005\n",
      "iteration: 4400 loss: 0.0078 lr: 0.005\n",
      "iteration: 4500 loss: 0.0075 lr: 0.005\n",
      "iteration: 4600 loss: 0.0070 lr: 0.005\n",
      "iteration: 4700 loss: 0.0069 lr: 0.005\n",
      "iteration: 4800 loss: 0.0067 lr: 0.005\n",
      "iteration: 4900 loss: 0.0069 lr: 0.005\n",
      "iteration: 5000 loss: 0.0068 lr: 0.005\n",
      "iteration: 5100 loss: 0.0065 lr: 0.005\n",
      "iteration: 5200 loss: 0.0072 lr: 0.005\n",
      "iteration: 5300 loss: 0.0069 lr: 0.005\n",
      "iteration: 5400 loss: 0.0064 lr: 0.005\n",
      "iteration: 5500 loss: 0.0067 lr: 0.005\n",
      "iteration: 5600 loss: 0.0068 lr: 0.005\n",
      "iteration: 5700 loss: 0.0068 lr: 0.005\n",
      "iteration: 5800 loss: 0.0070 lr: 0.005\n",
      "iteration: 5900 loss: 0.0058 lr: 0.005\n",
      "iteration: 6000 loss: 0.0065 lr: 0.005\n",
      "iteration: 6100 loss: 0.0063 lr: 0.005\n",
      "iteration: 6200 loss: 0.0066 lr: 0.005\n",
      "iteration: 6300 loss: 0.0065 lr: 0.005\n",
      "iteration: 6400 loss: 0.0059 lr: 0.005\n",
      "iteration: 6500 loss: 0.0066 lr: 0.005\n",
      "iteration: 6600 loss: 0.0065 lr: 0.005\n",
      "iteration: 6700 loss: 0.0074 lr: 0.005\n",
      "iteration: 6800 loss: 0.0069 lr: 0.005\n",
      "iteration: 6900 loss: 0.0065 lr: 0.005\n",
      "iteration: 7000 loss: 0.0063 lr: 0.005\n",
      "iteration: 7100 loss: 0.0062 lr: 0.005\n",
      "iteration: 7200 loss: 0.0067 lr: 0.005\n",
      "iteration: 7300 loss: 0.0064 lr: 0.005\n",
      "iteration: 7400 loss: 0.0061 lr: 0.005\n",
      "iteration: 7500 loss: 0.0061 lr: 0.005\n",
      "iteration: 7600 loss: 0.0062 lr: 0.005\n",
      "iteration: 7700 loss: 0.0067 lr: 0.005\n",
      "iteration: 7800 loss: 0.0062 lr: 0.005\n",
      "iteration: 7900 loss: 0.0060 lr: 0.005\n",
      "iteration: 8000 loss: 0.0058 lr: 0.005\n",
      "iteration: 8100 loss: 0.0061 lr: 0.005\n",
      "iteration: 8200 loss: 0.0055 lr: 0.005\n",
      "iteration: 8300 loss: 0.0058 lr: 0.005\n",
      "iteration: 8400 loss: 0.0060 lr: 0.005\n",
      "iteration: 8500 loss: 0.0055 lr: 0.005\n",
      "iteration: 8600 loss: 0.0061 lr: 0.005\n",
      "iteration: 8700 loss: 0.0060 lr: 0.005\n",
      "iteration: 8800 loss: 0.0058 lr: 0.005\n",
      "iteration: 8900 loss: 0.0058 lr: 0.005\n",
      "iteration: 9000 loss: 0.0066 lr: 0.005\n",
      "iteration: 9100 loss: 0.0059 lr: 0.005\n",
      "iteration: 9200 loss: 0.0060 lr: 0.005\n",
      "iteration: 9300 loss: 0.0058 lr: 0.005\n",
      "iteration: 9400 loss: 0.0062 lr: 0.005\n",
      "iteration: 9500 loss: 0.0061 lr: 0.005\n",
      "iteration: 9600 loss: 0.0048 lr: 0.005\n",
      "iteration: 9700 loss: 0.0055 lr: 0.005\n",
      "iteration: 9800 loss: 0.0052 lr: 0.005\n",
      "iteration: 9900 loss: 0.0056 lr: 0.005\n",
      "iteration: 10000 loss: 0.0059 lr: 0.005\n",
      "iteration: 10100 loss: 0.0076 lr: 0.02\n",
      "iteration: 10200 loss: 0.0089 lr: 0.02\n",
      "iteration: 10300 loss: 0.0083 lr: 0.02\n",
      "iteration: 10400 loss: 0.0088 lr: 0.02\n",
      "iteration: 10500 loss: 0.0088 lr: 0.02\n",
      "iteration: 10600 loss: 0.0082 lr: 0.02\n",
      "iteration: 10700 loss: 0.0076 lr: 0.02\n",
      "iteration: 10800 loss: 0.0073 lr: 0.02\n",
      "iteration: 10900 loss: 0.0091 lr: 0.02\n",
      "iteration: 11000 loss: 0.0079 lr: 0.02\n",
      "iteration: 11100 loss: 0.0074 lr: 0.02\n",
      "iteration: 11200 loss: 0.0074 lr: 0.02\n",
      "iteration: 11300 loss: 0.0066 lr: 0.02\n",
      "iteration: 11400 loss: 0.0070 lr: 0.02\n",
      "iteration: 11500 loss: 0.0072 lr: 0.02\n",
      "iteration: 11600 loss: 0.0069 lr: 0.02\n",
      "iteration: 11700 loss: 0.0070 lr: 0.02\n",
      "iteration: 11800 loss: 0.0065 lr: 0.02\n",
      "iteration: 11900 loss: 0.0073 lr: 0.02\n",
      "iteration: 12000 loss: 0.0071 lr: 0.02\n",
      "iteration: 12100 loss: 0.0062 lr: 0.02\n",
      "iteration: 12200 loss: 0.0066 lr: 0.02\n",
      "iteration: 12300 loss: 0.0067 lr: 0.02\n",
      "iteration: 12400 loss: 0.0065 lr: 0.02\n",
      "iteration: 12500 loss: 0.0063 lr: 0.02\n",
      "iteration: 12600 loss: 0.0060 lr: 0.02\n",
      "iteration: 12700 loss: 0.0058 lr: 0.02\n",
      "iteration: 12800 loss: 0.0064 lr: 0.02\n",
      "iteration: 12900 loss: 0.0059 lr: 0.02\n",
      "iteration: 13000 loss: 0.0055 lr: 0.02\n",
      "iteration: 13100 loss: 0.0059 lr: 0.02\n",
      "iteration: 13200 loss: 0.0062 lr: 0.02\n",
      "iteration: 13300 loss: 0.0063 lr: 0.02\n",
      "iteration: 13400 loss: 0.0055 lr: 0.02\n",
      "iteration: 13500 loss: 0.0059 lr: 0.02\n",
      "iteration: 13600 loss: 0.0055 lr: 0.02\n",
      "iteration: 13700 loss: 0.0045 lr: 0.02\n",
      "iteration: 13800 loss: 0.0056 lr: 0.02\n",
      "iteration: 13900 loss: 0.0056 lr: 0.02\n",
      "iteration: 14000 loss: 0.0056 lr: 0.02\n",
      "iteration: 14100 loss: 0.0055 lr: 0.02\n",
      "iteration: 14200 loss: 0.0060 lr: 0.02\n",
      "iteration: 14300 loss: 0.0057 lr: 0.02\n",
      "iteration: 14400 loss: 0.0051 lr: 0.02\n",
      "iteration: 14500 loss: 0.0056 lr: 0.02\n",
      "iteration: 14600 loss: 0.0047 lr: 0.02\n",
      "iteration: 14700 loss: 0.0052 lr: 0.02\n",
      "iteration: 14800 loss: 0.0052 lr: 0.02\n",
      "iteration: 14900 loss: 0.0051 lr: 0.02\n",
      "iteration: 15000 loss: 0.0054 lr: 0.02\n",
      "iteration: 15100 loss: 0.0053 lr: 0.02\n",
      "iteration: 15200 loss: 0.0050 lr: 0.02\n",
      "iteration: 15300 loss: 0.0058 lr: 0.02\n",
      "iteration: 15400 loss: 0.0054 lr: 0.02\n",
      "iteration: 15500 loss: 0.0053 lr: 0.02\n",
      "iteration: 15600 loss: 0.0048 lr: 0.02\n",
      "iteration: 15700 loss: 0.0048 lr: 0.02\n",
      "iteration: 15800 loss: 0.0052 lr: 0.02\n",
      "iteration: 15900 loss: 0.0052 lr: 0.02\n",
      "iteration: 16000 loss: 0.0050 lr: 0.02\n",
      "iteration: 16100 loss: 0.0046 lr: 0.02\n",
      "iteration: 16200 loss: 0.0046 lr: 0.02\n",
      "iteration: 16300 loss: 0.0044 lr: 0.02\n",
      "iteration: 16400 loss: 0.0040 lr: 0.02\n",
      "iteration: 16500 loss: 0.0047 lr: 0.02\n",
      "iteration: 16600 loss: 0.0048 lr: 0.02\n",
      "iteration: 16700 loss: 0.0052 lr: 0.02\n",
      "iteration: 16800 loss: 0.0050 lr: 0.02\n",
      "iteration: 16900 loss: 0.0055 lr: 0.02\n",
      "iteration: 17000 loss: 0.0053 lr: 0.02\n",
      "iteration: 17100 loss: 0.0044 lr: 0.02\n",
      "iteration: 17200 loss: 0.0043 lr: 0.02\n",
      "iteration: 17300 loss: 0.0045 lr: 0.02\n",
      "iteration: 17400 loss: 0.0044 lr: 0.02\n",
      "iteration: 17500 loss: 0.0048 lr: 0.02\n",
      "iteration: 17600 loss: 0.0046 lr: 0.02\n",
      "iteration: 17700 loss: 0.0051 lr: 0.02\n",
      "iteration: 17800 loss: 0.0049 lr: 0.02\n",
      "iteration: 17900 loss: 0.0049 lr: 0.02\n",
      "iteration: 18000 loss: 0.0041 lr: 0.02\n",
      "iteration: 18100 loss: 0.0044 lr: 0.02\n",
      "iteration: 18200 loss: 0.0043 lr: 0.02\n",
      "iteration: 18300 loss: 0.0045 lr: 0.02\n",
      "iteration: 18400 loss: 0.0044 lr: 0.02\n",
      "iteration: 18500 loss: 0.0043 lr: 0.02\n",
      "iteration: 18600 loss: 0.0048 lr: 0.02\n",
      "iteration: 18700 loss: 0.0050 lr: 0.02\n",
      "iteration: 18800 loss: 0.0044 lr: 0.02\n",
      "iteration: 18900 loss: 0.0043 lr: 0.02\n",
      "iteration: 19000 loss: 0.0041 lr: 0.02\n",
      "iteration: 19100 loss: 0.0045 lr: 0.02\n",
      "iteration: 19200 loss: 0.0047 lr: 0.02\n",
      "iteration: 19300 loss: 0.0046 lr: 0.02\n",
      "iteration: 19400 loss: 0.0041 lr: 0.02\n",
      "iteration: 19500 loss: 0.0038 lr: 0.02\n",
      "iteration: 19600 loss: 0.0040 lr: 0.02\n",
      "iteration: 19700 loss: 0.0044 lr: 0.02\n",
      "iteration: 19800 loss: 0.0037 lr: 0.02\n",
      "iteration: 19900 loss: 0.0039 lr: 0.02\n",
      "iteration: 20000 loss: 0.0045 lr: 0.02\n",
      "iteration: 20100 loss: 0.0041 lr: 0.02\n",
      "iteration: 20200 loss: 0.0038 lr: 0.02\n",
      "iteration: 20300 loss: 0.0051 lr: 0.02\n",
      "iteration: 20400 loss: 0.0041 lr: 0.02\n",
      "iteration: 20500 loss: 0.0040 lr: 0.02\n",
      "iteration: 20600 loss: 0.0044 lr: 0.02\n",
      "iteration: 20700 loss: 0.0042 lr: 0.02\n",
      "iteration: 20800 loss: 0.0048 lr: 0.02\n",
      "iteration: 20900 loss: 0.0049 lr: 0.02\n",
      "iteration: 21000 loss: 0.0038 lr: 0.02\n",
      "iteration: 21100 loss: 0.0039 lr: 0.02\n",
      "iteration: 21200 loss: 0.0039 lr: 0.02\n",
      "iteration: 21300 loss: 0.0039 lr: 0.02\n",
      "iteration: 21400 loss: 0.0041 lr: 0.02\n",
      "iteration: 21500 loss: 0.0035 lr: 0.02\n",
      "iteration: 21600 loss: 0.0036 lr: 0.02\n",
      "iteration: 21700 loss: 0.0044 lr: 0.02\n",
      "iteration: 21800 loss: 0.0038 lr: 0.02\n",
      "iteration: 21900 loss: 0.0042 lr: 0.02\n",
      "iteration: 22000 loss: 0.0038 lr: 0.02\n",
      "iteration: 22100 loss: 0.0038 lr: 0.02\n",
      "iteration: 22200 loss: 0.0043 lr: 0.02\n",
      "iteration: 22300 loss: 0.0038 lr: 0.02\n",
      "iteration: 22400 loss: 0.0037 lr: 0.02\n",
      "iteration: 22500 loss: 0.0041 lr: 0.02\n",
      "iteration: 22600 loss: 0.0038 lr: 0.02\n",
      "iteration: 22700 loss: 0.0039 lr: 0.02\n",
      "iteration: 22800 loss: 0.0039 lr: 0.02\n",
      "iteration: 22900 loss: 0.0031 lr: 0.02\n",
      "iteration: 23000 loss: 0.0039 lr: 0.02\n",
      "iteration: 23100 loss: 0.0038 lr: 0.02\n",
      "iteration: 23200 loss: 0.0038 lr: 0.02\n",
      "iteration: 23300 loss: 0.0038 lr: 0.02\n",
      "iteration: 23400 loss: 0.0033 lr: 0.02\n",
      "iteration: 23500 loss: 0.0037 lr: 0.02\n",
      "iteration: 23600 loss: 0.0036 lr: 0.02\n",
      "iteration: 23700 loss: 0.0037 lr: 0.02\n",
      "iteration: 23800 loss: 0.0039 lr: 0.02\n",
      "iteration: 23900 loss: 0.0039 lr: 0.02\n",
      "iteration: 24000 loss: 0.0038 lr: 0.02\n",
      "iteration: 24100 loss: 0.0038 lr: 0.02\n",
      "iteration: 24200 loss: 0.0034 lr: 0.02\n",
      "iteration: 24300 loss: 0.0039 lr: 0.02\n",
      "iteration: 24400 loss: 0.0040 lr: 0.02\n",
      "iteration: 24500 loss: 0.0041 lr: 0.02\n",
      "iteration: 24600 loss: 0.0033 lr: 0.02\n",
      "iteration: 24700 loss: 0.0034 lr: 0.02\n",
      "iteration: 24800 loss: 0.0040 lr: 0.02\n",
      "iteration: 24900 loss: 0.0034 lr: 0.02\n",
      "iteration: 25000 loss: 0.0035 lr: 0.02\n",
      "iteration: 25100 loss: 0.0038 lr: 0.02\n",
      "iteration: 25200 loss: 0.0035 lr: 0.02\n",
      "iteration: 25300 loss: 0.0036 lr: 0.02\n",
      "iteration: 25400 loss: 0.0037 lr: 0.02\n",
      "iteration: 25500 loss: 0.0037 lr: 0.02\n",
      "iteration: 25600 loss: 0.0034 lr: 0.02\n",
      "iteration: 25700 loss: 0.0034 lr: 0.02\n",
      "iteration: 25800 loss: 0.0035 lr: 0.02\n",
      "iteration: 25900 loss: 0.0031 lr: 0.02\n",
      "iteration: 26000 loss: 0.0034 lr: 0.02\n",
      "iteration: 26100 loss: 0.0039 lr: 0.02\n",
      "iteration: 26200 loss: 0.0036 lr: 0.02\n",
      "iteration: 26300 loss: 0.0034 lr: 0.02\n",
      "iteration: 26400 loss: 0.0038 lr: 0.02\n",
      "iteration: 26500 loss: 0.0033 lr: 0.02\n",
      "iteration: 26600 loss: 0.0033 lr: 0.02\n",
      "iteration: 26700 loss: 0.0032 lr: 0.02\n",
      "iteration: 26800 loss: 0.0034 lr: 0.02\n",
      "iteration: 26900 loss: 0.0028 lr: 0.02\n",
      "iteration: 27000 loss: 0.0032 lr: 0.02\n",
      "iteration: 27100 loss: 0.0032 lr: 0.02\n",
      "iteration: 27200 loss: 0.0035 lr: 0.02\n",
      "iteration: 27300 loss: 0.0034 lr: 0.02\n",
      "iteration: 27400 loss: 0.0037 lr: 0.02\n",
      "iteration: 27500 loss: 0.0036 lr: 0.02\n",
      "iteration: 27600 loss: 0.0031 lr: 0.02\n",
      "iteration: 27700 loss: 0.0031 lr: 0.02\n",
      "iteration: 27800 loss: 0.0034 lr: 0.02\n",
      "iteration: 27900 loss: 0.0036 lr: 0.02\n",
      "iteration: 28000 loss: 0.0033 lr: 0.02\n",
      "iteration: 28100 loss: 0.0035 lr: 0.02\n",
      "iteration: 28200 loss: 0.0029 lr: 0.02\n",
      "iteration: 28300 loss: 0.0029 lr: 0.02\n",
      "iteration: 28400 loss: 0.0031 lr: 0.02\n",
      "iteration: 28500 loss: 0.0032 lr: 0.02\n",
      "iteration: 28600 loss: 0.0030 lr: 0.02\n",
      "iteration: 28700 loss: 0.0032 lr: 0.02\n",
      "iteration: 28800 loss: 0.0033 lr: 0.02\n",
      "iteration: 28900 loss: 0.0031 lr: 0.02\n",
      "iteration: 29000 loss: 0.0028 lr: 0.02\n",
      "iteration: 29100 loss: 0.0029 lr: 0.02\n",
      "iteration: 29200 loss: 0.0033 lr: 0.02\n",
      "iteration: 29300 loss: 0.0031 lr: 0.02\n",
      "iteration: 29400 loss: 0.0036 lr: 0.02\n",
      "iteration: 29500 loss: 0.0033 lr: 0.02\n",
      "iteration: 29600 loss: 0.0035 lr: 0.02\n",
      "iteration: 29700 loss: 0.0036 lr: 0.02\n",
      "iteration: 29800 loss: 0.0034 lr: 0.02\n",
      "iteration: 29900 loss: 0.0032 lr: 0.02\n",
      "iteration: 30000 loss: 0.0029 lr: 0.02\n",
      "iteration: 30100 loss: 0.0033 lr: 0.02\n",
      "iteration: 30200 loss: 0.0032 lr: 0.02\n",
      "iteration: 30300 loss: 0.0036 lr: 0.02\n",
      "iteration: 30400 loss: 0.0033 lr: 0.02\n",
      "iteration: 30500 loss: 0.0028 lr: 0.02\n",
      "iteration: 30600 loss: 0.0030 lr: 0.02\n",
      "iteration: 30700 loss: 0.0033 lr: 0.02\n",
      "iteration: 30800 loss: 0.0033 lr: 0.02\n",
      "iteration: 30900 loss: 0.0031 lr: 0.02\n",
      "iteration: 31000 loss: 0.0031 lr: 0.02\n",
      "iteration: 31100 loss: 0.0032 lr: 0.02\n",
      "iteration: 31200 loss: 0.0033 lr: 0.02\n",
      "iteration: 31300 loss: 0.0028 lr: 0.02\n",
      "iteration: 31400 loss: 0.0036 lr: 0.02\n",
      "iteration: 31500 loss: 0.0029 lr: 0.02\n",
      "iteration: 31600 loss: 0.0026 lr: 0.02\n",
      "iteration: 31700 loss: 0.0032 lr: 0.02\n",
      "iteration: 31800 loss: 0.0032 lr: 0.02\n",
      "iteration: 31900 loss: 0.0026 lr: 0.02\n",
      "iteration: 32000 loss: 0.0030 lr: 0.02\n",
      "iteration: 32100 loss: 0.0027 lr: 0.02\n",
      "iteration: 32200 loss: 0.0032 lr: 0.02\n",
      "iteration: 32300 loss: 0.0030 lr: 0.02\n",
      "iteration: 32400 loss: 0.0031 lr: 0.02\n",
      "iteration: 32500 loss: 0.0030 lr: 0.02\n",
      "iteration: 32600 loss: 0.0029 lr: 0.02\n",
      "iteration: 32700 loss: 0.0033 lr: 0.02\n",
      "iteration: 32800 loss: 0.0028 lr: 0.02\n",
      "iteration: 32900 loss: 0.0034 lr: 0.02\n",
      "iteration: 33000 loss: 0.0028 lr: 0.02\n",
      "iteration: 33100 loss: 0.0032 lr: 0.02\n",
      "iteration: 33200 loss: 0.0028 lr: 0.02\n",
      "iteration: 33300 loss: 0.0030 lr: 0.02\n",
      "iteration: 33400 loss: 0.0028 lr: 0.02\n",
      "iteration: 33500 loss: 0.0030 lr: 0.02\n",
      "iteration: 33600 loss: 0.0028 lr: 0.02\n",
      "iteration: 33700 loss: 0.0033 lr: 0.02\n",
      "iteration: 33800 loss: 0.0032 lr: 0.02\n",
      "iteration: 33900 loss: 0.0035 lr: 0.02\n",
      "iteration: 34000 loss: 0.0029 lr: 0.02\n",
      "iteration: 34100 loss: 0.0030 lr: 0.02\n",
      "iteration: 34200 loss: 0.0033 lr: 0.02\n",
      "iteration: 34300 loss: 0.0026 lr: 0.02\n",
      "iteration: 34400 loss: 0.0029 lr: 0.02\n",
      "iteration: 34500 loss: 0.0031 lr: 0.02\n",
      "iteration: 34600 loss: 0.0030 lr: 0.02\n",
      "iteration: 34700 loss: 0.0028 lr: 0.02\n",
      "iteration: 34800 loss: 0.0028 lr: 0.02\n",
      "iteration: 34900 loss: 0.0026 lr: 0.02\n",
      "iteration: 35000 loss: 0.0027 lr: 0.02\n",
      "iteration: 35100 loss: 0.0030 lr: 0.02\n",
      "iteration: 35200 loss: 0.0029 lr: 0.02\n",
      "iteration: 35300 loss: 0.0032 lr: 0.02\n",
      "iteration: 35400 loss: 0.0027 lr: 0.02\n",
      "iteration: 35500 loss: 0.0029 lr: 0.02\n",
      "iteration: 35600 loss: 0.0026 lr: 0.02\n",
      "iteration: 35700 loss: 0.0031 lr: 0.02\n",
      "iteration: 35800 loss: 0.0027 lr: 0.02\n",
      "iteration: 35900 loss: 0.0030 lr: 0.02\n",
      "iteration: 36000 loss: 0.0026 lr: 0.02\n",
      "iteration: 36100 loss: 0.0031 lr: 0.02\n",
      "iteration: 36200 loss: 0.0027 lr: 0.02\n",
      "iteration: 36300 loss: 0.0030 lr: 0.02\n",
      "iteration: 36400 loss: 0.0028 lr: 0.02\n",
      "iteration: 36500 loss: 0.0025 lr: 0.02\n",
      "iteration: 36600 loss: 0.0029 lr: 0.02\n",
      "iteration: 36700 loss: 0.0024 lr: 0.02\n",
      "iteration: 36800 loss: 0.0025 lr: 0.02\n",
      "iteration: 36900 loss: 0.0026 lr: 0.02\n",
      "iteration: 37000 loss: 0.0025 lr: 0.02\n",
      "iteration: 37100 loss: 0.0027 lr: 0.02\n",
      "iteration: 37200 loss: 0.0029 lr: 0.02\n",
      "iteration: 37300 loss: 0.0029 lr: 0.02\n",
      "iteration: 37400 loss: 0.0026 lr: 0.02\n",
      "iteration: 37500 loss: 0.0025 lr: 0.02\n",
      "iteration: 37600 loss: 0.0025 lr: 0.02\n",
      "iteration: 37700 loss: 0.0028 lr: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdeeplabcut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisplayiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaveiters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:284\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix, superanimal_name, superanimal_transfer_learning)\u001b[0m\n\u001b[1;32m    273\u001b[0m         train(\n\u001b[1;32m    274\u001b[0m             \u001b[38;5;28mstr\u001b[39m(poseconfigfile),\n\u001b[1;32m    275\u001b[0m             displayiters,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m             allow_growth\u001b[38;5;241m=\u001b[39mallow_growth,\n\u001b[1;32m    281\u001b[0m         )  \u001b[38;5;66;03m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;28mstr\u001b[39m(start_path))\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/training.py:273\u001b[0m, in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix, superanimal_name, superanimal_transfer_learning)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeeplabcut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpose_estimation_tensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelecting single-animal trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 273\u001b[0m         \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mposeconfigfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisplayiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m            \u001b[49m\u001b[43msaveiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmaxiters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_to_keep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_snapshots_to_keep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeepdeconvweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdeconvweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pass on path and file name for pose_cfg.yaml!\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/core/train.py:287\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    284\u001b[0m     current_lr \u001b[38;5;241m=\u001b[39m lr_gen\u001b[38;5;241m.\u001b[39mget_lr(it \u001b[38;5;241m-\u001b[39m start_iter)\n\u001b[1;32m    285\u001b[0m     lr_dict \u001b[38;5;241m=\u001b[39m {learning_rate: current_lr}\n\u001b[0;32m--> 287\u001b[0m [_, loss_val, summary] \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmerged_summaries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_dict\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m cum_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_val\n\u001b[1;32m    291\u001b[0m train_writer\u001b[38;5;241m.\u001b[39madd_summary(summary, it)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, shuffle=1, displayiters=100, saveiters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESNewCameraApr19/FESNewCamera_Jake95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/dlc-models/iteration-0/FESNewCameraApr19-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'],\n",
      " 'alpha_r': 0.02,\n",
      " 'apply_prob': 0.5,\n",
      " 'batch_size': 1,\n",
      " 'contrast': {'clahe': True,\n",
      "              'claheratio': 0.1,\n",
      "              'histeq': True,\n",
      "              'histeqratio': 0.1},\n",
      " 'convolution': {'edge': False,\n",
      "                 'emboss': {'alpha': [0.0, 1.0], 'strength': [0.5, 1.5]},\n",
      "                 'embossratio': 0.1,\n",
      "                 'sharpen': False,\n",
      "                 'sharpenratio': 0.3},\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESNewCameraApr19/FESNewCamera_Jake95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'decay_steps': 30000,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'lr_init': 0.0005,\n",
      " 'max_input_size': 2000,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESNewCameraApr19/Documentation_data-FESNewCamera_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_stage': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/dlc-models/iteration-0/FESNewCameraApr19-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/jakejoseph/anaconda3/envs/DLCGPU/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DLC_resnet50_FESNewCameraApr19shuffle1_50000  with # of training iterations: 50000\n",
      "Running evaluation ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:19,  1.03it/s]\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/pose_estimation_tensorflow/core/evaluate.py:930: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  DataMachine.to_hdf(resultsfilename, \"df_with_missing\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis is done and the results are stored (see evaluation-results) for snapshot:  snapshot-50000\n",
      "Results for 50000  training iterations: 95 1 train error: 2.36 pixels. Test error: 28.35  pixels.\n",
      "With pcutoff of 0.6  train error: 2.36 pixels. Test error: 33.95 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "Plotting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  DataCombined[loopscorer][bp][\"y\"][imagenr]\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:68: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  + DataCombined[loopscorer][bp][\"x\"][imagenr]\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:71: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  int(DataCombined[loopscorer][bp][\"y\"][imagenr]),\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:72: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  int(DataCombined[loopscorer][bp][\"x\"][imagenr]),\n",
      "/home/jakejoseph/Desktop/Joseph_Code/DeepLabCut/deeplabcut/utils/visualization.py:75: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  p = DataCombined[loopscorer][bp][\"likelihood\"][imagenr]\n",
      "100%|| 20/20 [00:14<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "Please check the results, then choose the best model (snapshot) for prediction. You can update the config.yaml file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise, consider adding more labeled-data and retraining the network (see DeepLabCut workflow Fig 2, Nath 2019)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACBQAAAYTCAYAAABJn/nKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA9aklEQVR4nOzaQREAIRDAsOP8e16+zFQAPBIFFdA1Mx8AAAAAAAAAwOm/HQAAAAAAAAAAvMdQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAAAAYSgAAAAAAAAAAMJQAAAAAAAAAACEoQAAAAAAAAAACEMBAAAAAAAAABCGAgAAAAAAAAAgDAUAAAAAAAAAQBgKAAAAAAAAAIAwFAAAAAAAAOx27UAAAAAAQJC/9QArFEcAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAIBQAAAAAAAADACAUAAAAAAAAAwAgFAAAAAAAAAMAEbuwPI0mYvtwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 2048x1536 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path,Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-2000 for model /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "2024-06-03 10:17:06.392409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-03 10:17:06.392612: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.392653: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.392684: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.392715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.413813: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.413878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/jakejoseph/anaconda3/envs/dlcv22/lib/python3.10/site-packages/cv2/../../lib64:/usr/local/cuda/lib64:\n",
      "2024-06-03 10:17:06.413883: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-06-03 10:17:06.414816: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-03 10:17:06.429121: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/videos/Individual Motor Points top 03-05.mp4\n",
      "Loading  /home/jakejoseph/Desktop/Joseph_Code/FESNewCamera-Jake-2024-04-19/videos/Individual Motor Points top 03-05.mp4\n",
      "Duration of video [s]:  2355.87 , recorded with  30.0 fps!\n",
      "Overall # of frames:  70676  found with (before cropping) frame dimensions:  2048 1536\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 2024/70676 [31:23<21:18:04,  1.12s/it]"
     ]
    }
   ],
   "source": [
    "video = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4'\n",
    "config_path = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/config.yaml'\n",
    "deeplabcut.analyze_videos(config_path, video, shuffle=1, save_as_csv=True, videotype='mp4')\n",
    "# deeplabcut.extract_outlier_frames(config_path, video,outlieralgorithm='uncertain',p_bound=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4]],\n",
      " 'all_joints_names': ['DIP', 'PIP', 'MCP', 'Wrist', 'Forearm'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_FESFatigueMay31/FESFatigue_Jake95shuffle1.mat',\n",
      " 'dataset_type': 'imgaug',\n",
      " 'deterministic': False,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 1.0,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'mirror': False,\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 5,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': True,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'regularize': False,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n",
      "/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-37000 for model /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/dlc-models/iteration-0/FESFatigueMay31-trainset95shuffle1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 15:15:26.181305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 15:15:26.184512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 15:15:26.186092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 15:15:26.187708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 15:15:26.189234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-10 15:15:26.190945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9729 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4\n",
      "Loading  /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4\n",
      "Duration of video [s]:  765.73 , recorded with  30.0 fps!\n",
      "Overall # of frames:  22972  found with (before cropping) frame dimensions:  2048 1536\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 22972/22972 [26:29<00:00, 14.46it/s]\n",
      "/home/jakejoseph/anaconda3/envs/DEEPLABCUT/lib/python3.9/site-packages/deeplabcut/utils/auxiliaryfunctions.py:402: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  DataMachine.to_hdf(dataname, \"df_with_missing\", format=\"table\", mode=\"w\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract a few representative outlier frames.\n",
      "Starting to process video: /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4\n",
      "Loading /home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4 and data.\n",
      "Duration of video [s]: 765.73, recorded with 30.0 fps!\n",
      "Overall # of frames: 22972 with cropped frame dimensions: 2048 1536\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 3798/22972 [00:53<04:24, 72.54it/s]"
     ]
    }
   ],
   "source": [
    "videos = ['/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/ECRB_interleaved_stim_5_30_1.mp4',\n",
    "          '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/fatiguetest0523ecrb12_2.mp4',\n",
    "          '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/napierecrbfatigue_05_31_3_1.mp4']\n",
    "for video in videos:\n",
    "    deeplabcut.analyze_videos(config_path, video, shuffle=1, save_as_csv=True, videotype='mp4')\n",
    "    deeplabcut.create_labeled_video(config_path, video, videotype = 'mp4', save_frames=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_video = '/home/jakejoseph/Desktop/Joseph_Code/FESFatigue-Jake-2024-05-31/videos/fatiguetest0523ecrb12_2.mp4'\n",
    "# deeplabcut.extract_outlier_frames(config_path, new_video)\n",
    "deeplabcut.refine_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([29, 21,  4, 31, 25,  7, 32, 18, 30, 27, 20,  2, 19,  0, 14,  8, 26,\n",
       "          11,  1,  3, 10, 16, 34,  6, 22, 37, 12, 33, 17,  9, 23, 13, 15,  5,\n",
       "          36, 28]),\n",
       "   array([35, 24])))]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deeplabcut.merge_datasets(config_path)\n",
    "deeplabcut.create_training_dataset(config_path, net_type='resnet_50', augmenter_type='imgaug')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLCGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
