{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import other packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlclive import DLCLive, Processor\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_filepath = '/home/sachinks/Code/MyProjects/OctopusVideos1/Movement_class_and_timestamps_end_stim.xlsx'\n",
    "files_info = read_octopus_xlsx(xls_filepath)\n",
    "video_filename = 'elec_left_cord_100Hz_5mA_220616_134220_000'\n",
    "\n",
    "frame_count = None\n",
    "fps = 30"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video stream data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = f'/home/sachinks/Code/MyProjects/live_labelled/{video_filename}-1.mp4'\n",
    "\n",
    "model_type = \"mobilenet\" # \"resnet\"\n",
    "model_path = get_model_path(model_type)\n",
    "\n",
    "dlc_proc = Processor()\n",
    "dlc_live = DLCLive(\n",
    "    model_path,\n",
    "    processor=dlc_proc,\n",
    "    pcutoff=0.2,\n",
    "    resize=1,\n",
    "    # cropping=[100, 520, 210, 400],\n",
    "    # display=True,\n",
    "    # dynamic=(True, 0.2, 50)\n",
    "    )\n",
    "\n",
    "video = cv2.VideoCapture(video_path)\n",
    "frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start and end time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = files_info[files_info['File Name'] == video_filename]\n",
    "orig_start_end_time = row[['Start Time (s)', 'End Time (s)']].values[0]\n",
    "stim_time = row['End (s)'].values[0]\n",
    "\n",
    "start_end_time = add_time_margin(orig_start_end_time, total_time=frame_count/fps)\n",
    "start_end_time[0] = min(start_end_time[0], stim_time)\n",
    "start_end_time[1] += 4\n",
    "stim_f = int(fps*stim_time)\n",
    "\n",
    "start_f, end_f = (fps * start_end_time).astype(int)\n",
    "\n",
    "tx = np.linspace(start_end_time[0], start_end_time[1], end_f-start_f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_crop(pose, frame_shape, crop_params):\n",
    "    detected = pose[:, 2] > crop_params[0]\n",
    "\n",
    "    if np.any(detected):\n",
    "        x = pose[detected, 0]\n",
    "        y = pose[detected, 1]\n",
    "\n",
    "        x1 = int(max([0, int(np.amin(x)) - crop_params[1]]))\n",
    "        x2 = int(min([frame_shape[1], int(np.amax(x)) + crop_params[1]]))\n",
    "        y1 = int(max([0, int(np.amin(y)) - crop_params[1]]))\n",
    "        y2 = int(min([frame_shape[0], int(np.amax(y)) + crop_params[1]]))\n",
    "\n",
    "        dynamic_cropping = [x1, x2, y1, y2]\n",
    "        return dynamic_cropping\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean pose using likelihood\n",
    "DO_CLEANING = False\n",
    "p_threshold = 0.9\n",
    "\n",
    "feature_angles_array = []\n",
    "pose_speed_array = []\n",
    "\n",
    "prev_pose_xy = None\n",
    "\n",
    "crop_params = (p_threshold, 20) # threshold, margin\n",
    "\n",
    "full_dynamic_cropping = []\n",
    "\n",
    "# Read and save each frame\n",
    "for i in tqdm(range(frame_count)):\n",
    "    # get current pose\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # frame = rgb_to_grayscale(frame)\n",
    "    # TODO: find difference between init_inference & get_pose\n",
    "    curr_pose = None\n",
    "    if i == 0:\n",
    "        curr_pose = dlc_live.init_inference(frame)\n",
    "    else:\n",
    "        curr_pose = dlc_live.get_pose(frame)\n",
    "    \n",
    "    curr_pose_xy, curr_pose_p = curr_pose[:, :-1], curr_pose[:, -1]\n",
    "    if prev_pose_xy is None:\n",
    "        prev_pose_xy = curr_pose_xy\n",
    "\n",
    "    # replacing bad values with previous values\n",
    "    if DO_CLEANING:\n",
    "        bad_pose_mask = curr_pose_p < p_threshold\n",
    "        curr_pose_xy[bad_pose_mask] = prev_pose_xy[bad_pose_mask]\n",
    "\n",
    "    # do cropping\n",
    "    dynamic_cropping = do_crop(np.concatenate([curr_pose_xy, curr_pose_p[:, None]], axis=1), frame.shape, crop_params)\n",
    "\n",
    "    full_dynamic_cropping.append(dynamic_cropping)\n",
    "\n",
    "    # do stuffs with current pose\n",
    "    pose = np.stack([prev_pose_xy, curr_pose_xy])\n",
    "    feature_angles, pose_speed = extract_pose_features(pose)\n",
    "    feature_angles_array.append(feature_angles)\n",
    "    pose_speed_array.append(pose_speed)\n",
    "\n",
    "    # set previous pose\n",
    "    prev_pose_xy = curr_pose_xy\n",
    "\n",
    "feature_angles_array = np.array(feature_angles_array)\n",
    "pose_speed_array = np.array(pose_speed_array)\n",
    "\n",
    "full_dynamic_cropping = np.array(full_dynamic_cropping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(full_dynamic_cropping, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(video_filename)\n",
    "\n",
    "for i in range(5):\n",
    "    data_smoothed = smooth_data(pose_speed_array[start_f: end_f, i])\n",
    "    plt.plot(tx, data_smoothed, label=i)\n",
    "plt.title(\"Speed\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.legend(title=\"Keypoints\")\n",
    "plt.axvline(x=stim_time, color='orange', linewidth=3, alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "for k in range(3):\n",
    "    data_smoothed = smooth_data(feature_angles_array[start_f: end_f, k])\n",
    "    plt.plot(tx, data_smoothed, label=k)\n",
    "plt.title(\"Angle\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.legend(title=\"Angle\")\n",
    "plt.axvline(x=stim_time, color='orange', linewidth=3, alpha=0.5)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlc-live",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
